{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2690737a",
   "metadata": {},
   "source": [
    "Purpose: Turn text-data into data with appropriate values neccessary for functional RAGAS evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe365bb",
   "metadata": {},
   "source": [
    "Fetch documents (from only the SciComp wiki as of now) and put into accessable format for generation of expected outputs and creation of context later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097ef27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WEB LOADER\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import bs4 as bs\n",
    "import html2text\n",
    "from llama_index.core import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "data_path = '../data/janelia.org'  # Use './' to indicate the current directory\n",
    "text_maker = html2text.HTML2Text()\n",
    "text_maker.ignore_links = True\n",
    "text_maker.images_to_alt = True\n",
    "text_maker.single_line_break = True\n",
    "text_maker.ignore_emphasis = True\n",
    "SOURCE = \"Web\"\n",
    "\n",
    "\n",
    "def webpage_to_text(soup):\n",
    "    \"\"\" Convert a generic web page to searchable text\n",
    "    \"\"\"\n",
    "    title = soup.title.text\n",
    "    text = text_maker.handle(str(soup))\n",
    "    return title,text\n",
    "\n",
    "\n",
    "def janelia_org_to_text(soup):\n",
    "    \"\"\" Convert a janelia.org page to searchable text\n",
    "    \"\"\"\n",
    "    title = soup.title.text.replace(\" | Janelia Research Campus\",\"\")\n",
    "    content_sections = soup.find_all(\"section\", class_=\"content-section\")\n",
    "    if not content_sections:\n",
    "        return title,None\n",
    "    if len(content_sections) > 1:\n",
    "        raise Exception(\"More than one content section\")\n",
    "    content = content_sections[0]\n",
    "    # Remove useless content\n",
    "    for div in content.find_all(\"div\", {'class':['panels-ipe-label','secondary_menu']}):\n",
    "        div.decompose()\n",
    "    # Html2text smashes text together if only tags separate it\n",
    "    # This fix not only adds the spacing but also adds a separator for nav buttons\n",
    "    for span in content.find_all(\"span\", {'class':'button-wrapper'}):\n",
    "        sep = bs.NavigableString(\" / \")\n",
    "        span.insert(0, sep)\n",
    "    text = text_maker.handle(str(content))\n",
    "    return title,text\n",
    "\n",
    "\n",
    "def html_to_text(link, body):\n",
    "    \"\"\" Convert a web page to plain text for use as a GPT prompt.\n",
    "    \"\"\"\n",
    "    soup = bs.BeautifulSoup(body,'lxml')\n",
    "    if \"janelia.org\" in link:\n",
    "        title,text = janelia_org_to_text(soup)\n",
    "    else:\n",
    "        title,text = webpage_to_text(soup)\n",
    "    return title,text\n",
    "\n",
    "\n",
    "class WebSiteLoader():\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def create_document(self, name, title, link, doc_text):\n",
    "        metadata = {\"source\": self.data_path, \"title\": title, \"link\": link}\n",
    "        # Debugging: Print doc_text to ensure it's not empty\n",
    "        return [Document(page_content=doc_text, metadata=metadata)]\n",
    "    \n",
    "    def load_all_documents(self):\n",
    "        documents = []\n",
    "        for root, dirs, files in os.walk(self.data_path):\n",
    "            for name in files:\n",
    "                filepath = os.path.join(root, name)\n",
    "                with open(filepath) as f:\n",
    "                    link = f.readline().strip()\n",
    "                    body = f.read()\n",
    "                    title, text = html_to_text(link, body)\n",
    "                    \n",
    "                    \n",
    "                    # print(f\"Title: {title}\")\n",
    "                    # print(f\"Text: {text}\")\n",
    "                    if text:\n",
    "                        final_text = title + \"\\n\" + text\n",
    "                        with open('tempTestGen.txt', 'w') as file:\n",
    "                            file.write(final_text)\n",
    "                        loader = TextLoader(\"./tempTestGen.txt\")\n",
    "                        doc = loader.load()\n",
    "                        documents.append(doc)\n",
    "        return documents\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open output.txt in write mode\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d58422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ARCHIVED WIKI LOADRER\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "import html2text\n",
    "from llama_index.core import Document\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "SOURCE = \"Wiki\"\n",
    "\n",
    "text_maker = html2text.HTML2Text()\n",
    "text_maker.ignore_links = True\n",
    "text_maker.ignore_images = True\n",
    "\n",
    "\n",
    "def wiki_to_text(ancestors, title, authors, labels, body):\n",
    "    \"\"\" Convert a wiki document to plain text for use as a GPT prompt.\n",
    "    \"\"\"\n",
    "    body_text = text_maker.handle(body)\n",
    "    text =  f\"Title: {title}\\n\"\n",
    "    if authors: text += f\"Authors: {authors}\\n\" \n",
    "    if ancestors: text += f\"Ancestors: {ancestors}\\n\" \n",
    "    if labels: text += f\"Labels: {ancestors}\\n\"\n",
    "    text += f\"{body_text}\"\n",
    "    return text\n",
    "\n",
    "\n",
    "class WikiLoader():\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def create_document(self, name, title, link, doc_text):\n",
    "        metadata = {\"source\": self.data_path, \"title\": title, \"link\": link}\n",
    "        return [Document(page_content=doc_text, metadata=metadata)]\n",
    "\n",
    "    def load_all_documents(self):\n",
    "        documents = []\n",
    "        for root, dirs, files in os.walk(self.data_path):\n",
    "            for name in files:\n",
    "                filepath = os.path.join(root, name)\n",
    "                with open(filepath) as f:\n",
    "                    link = f.readline().rstrip()\n",
    "                    ancestors = f.readline().rstrip()\n",
    "                    title = f.readline().rstrip()\n",
    "                    authors = f.readline().rstrip()\n",
    "                    labels = f.readline().rstrip()\n",
    "                    body = re.sub('[\\n]+', '\\n', \"\".join(f.readlines()))\n",
    "                    text = wiki_to_text(ancestors, title, authors, labels, body)\n",
    "                    # doc = self.create_document(name, title, link, text)\n",
    "                    # documents.append(doc)\n",
    "                    if text:\n",
    "                        final_text = title + \"\\n\" + text\n",
    "                        with open('tempTestGen.txt', 'w') as file:\n",
    "                            file.write(final_text)\n",
    "                        loader = TextLoader(\"./tempTestGen.txt\")\n",
    "                        doc = loader.load()\n",
    "                        documents.append(doc)\n",
    "        return documents\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d48ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ARCHIVED SLACK LOADER\"\"\"\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from decimal import Decimal\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "SOURCE = \"Slack\"\n",
    "DOCUMENT_PAUSE_SECS = 300\n",
    "IGNORED_SUBTYPES = set(['channel_join','channel_leave','bot_message'])\n",
    "\n",
    "\n",
    "def get(dictionary, key):\n",
    "    \"\"\" Get the key out of the dictionary, if it exists. If not, return None.\n",
    "    \"\"\"\n",
    "    if dictionary and key in dictionary:\n",
    "        return dictionary[key]\n",
    "    return None\n",
    "\n",
    "\n",
    "def fix_text(text):\n",
    "    \"\"\" Standard transformations on text like squashing multiple newlines.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"\\n+\", \"\\n\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "class ArchivedSlackLoader():\n",
    "\n",
    "    def __init__(self, data_path, debug=False):\n",
    "        self.data_path = data_path\n",
    "        self.id2username = {}\n",
    "        self.id2realname = {}\n",
    "        self.channel2id = {}\n",
    "        self.debug = debug\n",
    "\n",
    "        for user in self.get_users():\n",
    "            id = user['id']\n",
    "            self.id2username[id] = user['name']\n",
    "            self.id2realname[id] = user['profile']['real_name']\n",
    "\n",
    "        logger.info(f\"Loaded {len(self.id2username)} users\")\n",
    "        for channel in self.get_channels():\n",
    "            logger.debug(f\"{channel['id']}: {channel['name']}\")\n",
    "            self.channel2id[channel['name']] = channel['id']\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.channel2id)} channels\")\n",
    "\n",
    "\n",
    "    def get_users(self):\n",
    "        \"\"\" Generator which returns users from the users.json file.\n",
    "        \"\"\"\n",
    "        with open(f\"{self.data_path}/users.json\", 'r') as f:\n",
    "            users = json.load(f)\n",
    "            for user in users:\n",
    "                yield user\n",
    "\n",
    "\n",
    "    def get_channels(self):\n",
    "        \"\"\" Generator which returns channels from the channels.json file.\n",
    "        \"\"\"\n",
    "        with open(f\"{self.data_path}/channels.json\", 'r') as f:\n",
    "            channels = json.load(f)\n",
    "            for channel in channels:\n",
    "                yield channel\n",
    "\n",
    "\n",
    "    def get_messages(self, channel_name):\n",
    "        \"\"\" Generator which returns messages from the json files in the given channel directory.\n",
    "        \"\"\"\n",
    "        for messages_file in glob.glob(f\"{self.data_path}/{channel_name}/*.json\"):\n",
    "            with open(messages_file, 'r') as f:\n",
    "                for message in json.load(f):\n",
    "                    yield message\n",
    "\n",
    "\n",
    "    def extract_text(self, elements):\n",
    "        \"\"\" Recursively parse an 'elements' structure, \n",
    "            converting user elements to their real names.\n",
    "        \"\"\"\n",
    "        text = ''\n",
    "        for element in elements:\n",
    "            if 'elements' in element:\n",
    "                text += self.extract_text(element['elements'])\n",
    "            el_type = get(element, 'type')\n",
    "            if el_type == 'text':\n",
    "                if get(get(element, 'style'), 'code'): text += '`'\n",
    "                text += element['text']\n",
    "                if get(get(element, 'style'), 'code'): text += '`'\n",
    "            elif el_type == 'link':\n",
    "                text += get(element, 'url')\n",
    "            elif el_type == 'rich_text_preformatted':\n",
    "                text += \"\\n\"\n",
    "            elif el_type == 'user':\n",
    "                user_id = element['user_id']\n",
    "                try:\n",
    "                    text += self.id2realname[user_id]\n",
    "                except KeyError:\n",
    "                    logger.error(f\"No such user '{user_id}'\")\n",
    "                    text += user_id\n",
    "\n",
    "        return text\n",
    "\n",
    "    def parse_message(self, message):\n",
    "        \"\"\" Parse a message into text that will be read by a GPT model. \n",
    "        \"\"\"\n",
    "        thread_id, text_msg = None, None\n",
    "        if get(message, 'type') == 'message':\n",
    "            if 'subtype' in message and get(message, 'subtype') in IGNORED_SUBTYPES:\n",
    "                pass\n",
    "            else:\n",
    "                ts = message['ts']\n",
    "                thread_ts = get(message, 'thread_ts') or ts\n",
    "                thread_id = Decimal(thread_ts)\n",
    "\n",
    "                # Translate user\n",
    "                user_id = message['user']\n",
    "                try:\n",
    "                    realname = self.id2realname[user_id]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        realname = message['user_profile']['display_name']\n",
    "                    except KeyError:\n",
    "                        realname = user_id\n",
    "                    \n",
    "                if 'blocks' in message:\n",
    "                    text = self.extract_text(message['blocks'])\n",
    "                else:\n",
    "                    text = message['text']\n",
    "                \n",
    "                text_msg = re.sub(\"<@(.*?)>\", lambda m: self.id2realname[m.group(1)], text)\n",
    "                text_msg = fix_text(text_msg)\n",
    "\n",
    "                if 'attachments' in message:\n",
    "                    for attachment in message['attachments']:\n",
    "                        if 'title' in attachment: text_msg += f\"\\n{fix_text(attachment['title'])}\"\n",
    "                        if 'text' in attachment: text_msg += f\"\\n{fix_text(attachment['text'])}\"\n",
    "                        \n",
    "                if 'files' in message:\n",
    "                    for file in message['files']:\n",
    "                        if 'name' in file:\n",
    "                            # There are several cases where a file doesn't have a name:\n",
    "                            # 1) The file has been deleted (mode=tombstone)\n",
    "                            # 2) We have no access (file_access=access_denied)\n",
    "                            text_msg += f\"\\n<{file['name']}>\"\n",
    "\n",
    "                if 'reactions' in message:\n",
    "                    text_msg += f\"\\nOthers reacted to the previous message with \"\n",
    "                    r = [f\"{reaction['name']} a total of {reaction['count']} times\" for reaction in message['reactions']]\n",
    "                    text_msg += \", and with \".join(r) + \".\"\n",
    "\n",
    "                text_msg = f\"{realname} said: {text_msg}\\n\"\n",
    "        \n",
    "        return thread_id, text_msg\n",
    "\n",
    "\n",
    "    def create_document(self, channel_id, ts, doc_text):\n",
    "        final_text = doc_text\n",
    "        with open('tempTestGen.txt', 'w') as file:\n",
    "            file.write(final_text)\n",
    "        loader = TextLoader(\"./tempTestGen.txt\")\n",
    "        \n",
    "        return loader.load()\n",
    "\n",
    "    def load_documents(self, channel_name):\n",
    "        channel_id = self.channel2id[channel_name]\n",
    "        messages = {}\n",
    "        for message in self.get_messages(channel_name):\n",
    "            try:\n",
    "                thread_id, text_msg = self.parse_message(message)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing message: {message}\")\n",
    "                raise e\n",
    "                \n",
    "            if thread_id and text_msg:\n",
    "                if thread_id not in messages:\n",
    "                    messages[thread_id] = []\n",
    "                messages[thread_id].append(text_msg)\n",
    "\n",
    "        prev_id = Decimal(0)\n",
    "        documents = []\n",
    "        doc_text = \"\"\n",
    "        start_ts = None\n",
    "\n",
    "        for thread_id in sorted(list(messages.keys())):\n",
    "\n",
    "            # Create a new document whenever messages are separated by a longer pause\n",
    "            if doc_text and thread_id-prev_id > DOCUMENT_PAUSE_SECS:\n",
    "                doc = self.create_document(channel_id, start_ts, doc_text)\n",
    "                documents.append(doc)\n",
    "                doc_text = \"\"\n",
    "                start_ts = None\n",
    "\n",
    "            logger.debug(thread_id)\n",
    "\n",
    "            # Starting timestamp for the next document\n",
    "            if not start_ts:\n",
    "                start_ts = str(thread_id)\n",
    "\n",
    "            # Add all messages from the current thread\n",
    "            for text_msg in messages[thread_id]:\n",
    "                doc_text += text_msg\n",
    "\n",
    "            prev_id = thread_id\n",
    "\n",
    "        # Add final document\n",
    "        doc = self.create_document(channel_id, start_ts, doc_text)\n",
    "        documents.append(doc)\n",
    "\n",
    "        return documents\n",
    "\n",
    "\n",
    "    def load_all_documents(self):\n",
    "        documents = []\n",
    "        for channel_name in self.channel2id.keys():\n",
    "            for doc in self.load_documents(channel_name):\n",
    "                documents.append(doc)\n",
    "        return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e912570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded 170 users\n",
      "INFO:__main__:Loaded 44 channels\n",
      "ERROR:__main__:No such user 'WAPC2SXJN'\n",
      "ERROR:__main__:No such user 'W8C6WFVM4'\n",
      "ERROR:__main__:No such user 'W9GJ4UF33'\n",
      "ERROR:__main__:No such user 'W0129A3DR8B'\n",
      "ERROR:__main__:No such user 'WBHHEM2AU'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'WA7Q7CKGS'\n",
      "ERROR:__main__:No such user 'U02QZ8GH64X'\n",
      "ERROR:__main__:No such user 'W013JPYQ5PA'\n",
      "ERROR:__main__:No such user 'W013JPYQ5PA'\n",
      "ERROR:__main__:No such user 'WD5FSBZTJ'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'UMVJ4KRV2'\n",
      "ERROR:__main__:No such user 'U03PL1HLZBP'\n",
      "ERROR:__main__:No such user 'U040HM3D0TU'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'U040HM3D0TU'\n",
      "ERROR:__main__:No such user 'U028YV8LZUP'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0182GKL7QR'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UFJ8DBDC3'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U0182GKL7QR'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UDM220J2W'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U4T03270V'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U4T03270V'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U016WBXDARX'\n",
      "ERROR:__main__:No such user 'U029QJUSZFB'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029QJUSZFB'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029QJUSZFB'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DOCUMENT LOADER ALL SOURCES\"\"\"\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# generator with openai models\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "# DONE: Recursively load all scraped files in the directory and its subdirectories\n",
    "# loader = TextLoader(\"./test.txt\")\n",
    "# documents = loader.load()\n",
    "# print(documents)\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import mimetypes\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\"\"\"ArchivedSlackLoader\n",
    "slack_to_2023-05-18\n",
    "\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "class DocumentLoader:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def load_documents(self):\n",
    "        all_documents = []\n",
    "        for folder_name in os.listdir(self.root_dir):\n",
    "            folder_path = os.path.join(self.root_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                if folder_name == \"wiki\":\n",
    "                    loader = WikiLoader(folder_path)\n",
    "                elif folder_name == \"slack\":\n",
    "                    # Specify the two subdirectories for slack\n",
    "                    subdirs = [\"janelia-software/slack_to_2023-05-18\"]\n",
    "                    for subdir in subdirs:\n",
    "                        subfolder_path = os.path.join(folder_path, subdir)\n",
    "                        # Check if the subdirectory exists\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            loader = ArchivedSlackLoader(subfolder_path)\n",
    "                            documents = loader.load_all_documents()\n",
    "                            # Take a random 10% sample\n",
    "                            # sample_size = max(1, len(documents) // 10)\n",
    "                            # documents_sample = random.sample(documents, sample_size)\n",
    "                            # all_documents.extend(documents_sample)\n",
    "                            all_documents.extend(documents)\n",
    "                elif folder_name == \"janelia.com\":\n",
    "                    loader = WebSiteLoader(folder_path)\n",
    "                else:\n",
    "                    continue  # Skip if folder doesn't match any criteria\n",
    "                # For non-slack directories\n",
    "                if folder_name != \"slack\":\n",
    "                    documents = loader.load_all_documents()\n",
    "                    # Take a random 10% sample\n",
    "                    # sample_size = max(1, len(documents) // 10)\n",
    "                    # documents_sample = random.sample(documents, sample_size)\n",
    "                    # all_documents.extend(documents_sample)\n",
    "                    all_documents.extend(documents)\n",
    "        return all_documents\n",
    "    \n",
    "    def test_load_documents(self):\n",
    "        # This method is for testing purposes and will only load the first document in each folder path\n",
    "        all_documents = []\n",
    "        for folder_name in os.listdir(self.root_dir):\n",
    "            folder_path = os.path.join(self.root_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                if folder_name == \"wiki\":\n",
    "                    loader = WikiLoader(folder_path)\n",
    "                elif folder_name == \"slack\":\n",
    "                    # Specify the two subdirectories for slack\n",
    "                    subdirs = [\"janelia-software/slack_to_2023-05-18\"]\n",
    "                    for subdir in subdirs:\n",
    "                        subfolder_path = os.path.join(folder_path, subdir)\n",
    "                        # Check if the subdirectory exists\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            loader = ArchivedSlackLoader(subfolder_path)\n",
    "                            documents = loader.load_all_documents()\n",
    "                            # Only load the first document for testing\n",
    "                            if documents:\n",
    "                                all_documents.append(documents[0])\n",
    "                elif folder_name == \"janelia.com\":\n",
    "                    loader = WebSiteLoader(folder_path)\n",
    "                else:\n",
    "                    continue  # Skip if folder doesn't match any criteria\n",
    "                # For non-slack directories\n",
    "                if folder_name != \"slack\":\n",
    "                    documents = loader.load_all_documents()\n",
    "                    # Only load the first document for testing\n",
    "                    if documents:\n",
    "                        all_documents.append(documents[0])\n",
    "        return all_documents\n",
    "\n",
    "# Assuming your data folder is at \"./data/\"\n",
    "loader = DocumentLoader(\"../../data\")\n",
    "documents = loader.test_load_documents()\n",
    "with open('documents.txt', 'w') as file:\n",
    "    for document in documents:\n",
    "        file.write(str(document) + '\\n')\n",
    "# # Assuming documents is a list of strings or convertible to string\n",
    "\n",
    "\n",
    "# Now `final_df` contains all the generated testsets in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bce0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b4bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a67d822bdcf4dbb8228579bf5749343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.docstore:Document [ID: 9009cf6d-f50a-42b0-a988-48b81e1156d3] has no filename, using `doc_id` instead\n",
      "INFO:ragas.testset.docstore:Document [ID: 9009cf6d-f50a-42b0-a988-48b81e1156d3] has no filename, using `doc_id` instead\n",
      "WARNING:ragas.testset.docstore:Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6fa8287e3a40eda9b16f2d6ca55e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server, e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\"\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server - e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states: \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\"\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server, e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\"\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of installing and configuring s3fs on the Scientific Computing Server?\"\n",
      "\n",
      "This question can be answered by referring to the \"Purpose\" section, which states that the server runs production services for the Janelia Workstation using Docker Swarm. Additionally, the \"Software\" section mentions that s3fs is used for mounting AWS S3 buckets.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 1 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of installing and configuring s3fs on the Scientific Computing Server?\"\n",
      "\n",
      "This question can be answered by referring to the \"Purpose\" section, which states that the server runs production services for the Janelia Workstation using Docker Swarm. Additionally, the \"Software\" section mentions that s3fs is used for mounting AWS S3 buckets.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 2 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of installing and configuring s3fs on the Scientific Computing Server?\"\n",
      "\n",
      "This question can be answered by referring to the \"Purpose\" section, which states that the server runs production services for the Janelia Workstation using Docker Swarm. Additionally, the \"Software\" section mentions that s3fs is used for mounting AWS S3 buckets.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 1 times\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 3 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of installing and configuring fuse for s3fs on the Scientific Computing Server?\"\n",
      "\n",
      "This question can be answered by referring to the \"s3fs\" section in the context, which explains that s3fs is used for mounting AWS S3 buckets.\n",
      "INFO:ragas.testset.evolutions:seed question generated: What is the purpose of running JACS containers on the Scientific Computing Server - e03u07?\n",
      "INFO:ragas.testset.evolutions:rewritten question: What is the purpose of running JACS containers on the Scientific Computing Server - e03u07?\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 4 times\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m     77\u001b[0m     test_size_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(document)) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     current_testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43msimple\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_context\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     current_testset \u001b[38;5;241m=\u001b[39m current_testset\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# current_testset.to_parquet('importMe.parquet', index=False)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/generator.py:210\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39madd_documents(\n\u001b[1;32m    207\u001b[0m     [Document\u001b[38;5;241m.\u001b[39mfrom_langchain_document(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    208\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_async\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/generator.py:303\u001b[0m, in \u001b[0;36mTestsetGenerator.generate\u001b[0;34m(self, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    300\u001b[0m         total_evolutions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     test_data_rows \u001b[38;5;241m=\u001b[39m \u001b[43mexec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m test_data_rows:\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:131\u001b[0m, in \u001b[0;36mExecutor.results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m executor_job\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mexecutor_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"RUN EVALS\"\"\"\n",
    "from datasets import Dataset\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "import pandas as pd\n",
    "import pyarrow \n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.testset.evolutions import Evolution\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# generator_llm = Ollama(model=\"llama3:70b\")\n",
    "# critic_llm = Ollama(model=\"llama3:70b\")\n",
    "\n",
    "# generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "# critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "# embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "\n",
    "\n",
    "# generator_llm = Ollama(model=\"phi\")\n",
    "# critic_llm = Ollama(model=\"phi\")\n",
    "\n",
    "\n",
    "generator_llm = Ollama(model=\"llama3\")\n",
    "critic_llm = Ollama(model=\"llama3\")\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"avr/sfr-embedding-mistral\"\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"curl http://e02u30.int.janelia.org:11434/api/generate -d '{\n",
    "  \"model\": \"llama3\",\n",
    "  \"prompt\":\"Why is the sky blue?\"\n",
    "}'\"\"\"\n",
    "# generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ") \n",
    "\n",
    "# current_testset = generator.generate_with_langchain_docs(document, test_size=1, distributions={\"simple\": 0.5, \"reasoning\": 0.25, \"multi_context\": 0.25})\n",
    "\n",
    "\n",
    "# Initialize an empty list to collect all testsets\n",
    "\n",
    "# Iterate over each document\n",
    "\n",
    "def datasetFix(df):\n",
    "    run_config = RunConfig()\n",
    "\n",
    "    columns_to_keep = ['question', 'ground_truth', 'contexts']\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    # Apply transformations\n",
    "    df['contexts'] = df['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "    df['ground_truth'] = df['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "all_data_df = pd.DataFrame()\n",
    "\n",
    "# evolution = Evolution(max_tries=1)\n",
    "\n",
    "for document in documents:\n",
    "    \n",
    "    test_size_gen = int(len(str(document)) // 500)\n",
    "    current_testset = generator.generate_with_langchain_docs(document, test_size=test_size_gen, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "    current_testset = current_testset.to_pandas()\n",
    "\n",
    "    # current_testset.to_parquet('importMe.parquet', index=False)\n",
    "    current_df = datasetFix(current_testset)\n",
    "\n",
    "    # current_df = datasetFix(current_testset)\n",
    "    \n",
    "    all_data_df = pd.concat([all_data_df, current_df], ignore_index=True)    # If this is the first iteration, set the DataFrame, otherwise append to it\n",
    "\n",
    "display(all_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b05cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d241aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Here is a question that can be fully answered from the given context:\\n\\n\"What is the purpose of the Scientific Computing Server, e03u07?\"\\n\\nThis question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.', 'Here is a question that can be fully answered from the given context:\\n\\n\"What is the purpose of the Scientific Computing Server - e03u07?\"\\n\\nThis question can be answered by reading the \"Purpose\" section of the context, which states: \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.', 'Here\\'s a question that can be fully answered from the given context:\\n\\n\"What is Davis Bennett\\'s comparison between using Numba and CuPy for accelerating array computing operations?\"\\n\\nThis question can be answered by referencing Davis Bennett\\'s statement about comparing the performance of a CUDA kernel jitted with Numba to the same operation on a CuPy array.']\n",
      "Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server, e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\n",
      "Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server - e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states: \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\n",
      "Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is Davis Bennett's comparison between using Numba and CuPy for accelerating array computing operations?\"\n",
      "\n",
      "This question can be answered by referencing Davis Bennett's statement about comparing the performance of a CUDA kernel jitted with Numba to the same operation on a CuPy array.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "questions_list = all_data_df['question'].tolist()\n",
    "print (questions_list)\n",
    "\n",
    "seen = set()\n",
    "questions_list = [x for x in questions_list if not (x in seen or seen.add(x))]\n",
    "\n",
    "for item in questions_list:\n",
    "    print(item)\n",
    "\n",
    "    \n",
    "\n",
    "# testset.to_json(\"testset.json\")\n",
    "# Creates dataset of ground truths contexts and questions for the testset\n",
    "# Missing answers column \n",
    "# On one medium size document, it took about 1 minutes to generate 10 questions and cost 3 dollars on OpenAI\n",
    "# Seems expensive when using gpt-4, is its use justified or does 3.5 get the job done?\n",
    "# Evaluate gpt-4 vs gpt-3.5-turbo-16k for RAGAS evaluation test data generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a0523",
   "metadata": {},
   "source": [
    "fetch the LLM's response and append to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862687da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The primary purpose of Akaike information crit...</td>\n",
       "      <td>[Mark Kittisopikul said: Greg Fleishman, I was...</td>\n",
       "      <td>AIC estimates the relative quality of each mod...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611382</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the Akaike information criterio...</td>\n",
       "      <td>[Mark Kittisopikul said: Greg Fleishman, I was...</td>\n",
       "      <td>AIC estimates the relative quality of statisti...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609881</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>AIC aims to reconcile the trade-off between th...</td>\n",
       "      <td>[Mark Kittisopikul said: Greg Fleishman, I was...</td>\n",
       "      <td>AIC aims to balance the trade-off between over...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713180</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The embedded ChatGPT-like interface has tricks...</td>\n",
       "      <td>[William Katz said: https://twitter.com/maxhod...</td>\n",
       "      <td>The embedded ChatGPT-like interface allows use...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Sequential storage can have benefits even in h...</td>\n",
       "      <td>[William Katz said: Some links from my second ...</td>\n",
       "      <td>Sequential storage has benefits in highly para...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.668477</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here's a rewritten question that conveys the s...</td>\n",
       "      <td>Sequential storage (i.e., trying to maximize a...</td>\n",
       "      <td>[William Katz said: Some links from my second ...</td>\n",
       "      <td>Sequential storage offers benefits for high-th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565915</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The matrix operations performed in this code s...</td>\n",
       "      <td>[.10534273, -0.5556871 ,\\n         0.8352932 ,...</td>\n",
       "      <td>Matrix multiplication and decomposition operat...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606350</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The test is checking the accuracy of the GGESE...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The test is checking the accuracy of the GGESE...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519669</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the QZ decomposition in numeric...</td>\n",
       "      <td>[.10534273, -0.5556871 ,\\n         0.8352932 ,...</td>\n",
       "      <td>The QZ decomposition in numerical computation ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The embedded ChatGPT-like interface has featur...</td>\n",
       "      <td>[William Katz said: https://twitter.com/maxhod...</td>\n",
       "      <td>The embedded ChatGPT-like interface allows for...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The test is checking the accuracy of the GGESE...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>Python 3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561170</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Python 3.10.6</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The kernel crash when using data augmentation ...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Based on the given context, here's a question ...</td>\n",
       "      <td>The issue causing the kernel crash when using ...</td>\n",
       "      <td>[.        ,  0.        ,  0.        ,  0.     ...</td>\n",
       "      <td>The Next Gen File Formats session at the OME c...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729890</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>During the Next Gen File Formats session at th...</td>\n",
       "      <td>[Ulrike Boehm said: For those of you intereste...</td>\n",
       "      <td>Yes, a matrix can be decomposed into its ortho...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.512027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[.10534273, -0.5556871 ,\\n         0.8352932 ,...</td>\n",
       "      <td>What is the topic of discussion at the OME ses...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What's on the agenda for the Next Gen File For...</td>\n",
       "      <td>During the OME conference next week they will ...</td>\n",
       "      <td>[Ulrike Boehm said: For those of you intereste...</td>\n",
       "      <td>Cristian Goina's code may behave differently w...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[.        ,  0.        ,  0.        ,  0.     ...</td>\n",
       "      <td>The 'Next Gen File Formats' session at the OME...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672138</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>During the 'Next Gen File Formats' session at ...</td>\n",
       "      <td>[Ulrike Boehm said: For those of you intereste...</td>\n",
       "      <td>To attach VSCode to a bsub session for remote ...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>To attach VSCode to a bsub session for remote ...</td>\n",
       "      <td>[Eric Wait said: Has anyone attached VScode to...</td>\n",
       "      <td>The array 'a' contains integer values, the arr...</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.540272</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Based on the given context, a question that ca...</td>\n",
       "      <td>The differences between the arrays 'a', 'b', a...</td>\n",
       "      <td>[ol=1.19209e-05\\nE   \\nE   Mismatched elements...</td>\n",
       "      <td>Gert-Jan Both made changes to the API of xray ...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Gert-Jan Both made some changes to the API of ...</td>\n",
       "      <td>[Gert-Jan Both said: Welcome everyone! As you ...</td>\n",
       "      <td>Running `Pkg.update()` in a Julia session upda...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568042</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Running Pkg.update() in a Julia session update...</td>\n",
       "      <td>[Mark Kittisopikul said: Something like the en...</td>\n",
       "      <td>The test is checking if the result of the GGE ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577780</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The test is checking if the result of the GGE ...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The test is checking if the result of the GGE ...</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The test is checking if the result of the GGE ...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The values are reconstructed at arbitrary loca...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394914</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>During warping, values for img must be reconst...</td>\n",
       "      <td>[Davis Bennett said: after rotation of the `[1...</td>\n",
       "      <td>The expected result of the `q @ s @ z.conj().T...</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The expected result of the q @ s @ z.conj().T ...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The QZ decomposition in linear algebra is util...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680793</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The purpose of the QZ decomposition in linear ...</td>\n",
       "      <td>[.10534273, -0.5556871 ,\\n         0.8352932 ,...</td>\n",
       "      <td>Integrating package management within a progra...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566521</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How does integrating package management within...</td>\n",
       "      <td>Integrating package management within a progra...</td>\n",
       "      <td>[Mark Kittisopikul said: Something like the en...</td>\n",
       "      <td>To establish a remote VScode dev env for bsub ...</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.490028</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>You can run a remote VScode session on the sub...</td>\n",
       "      <td>[Eric Wait said: Has anyone attached VScode to...</td>\n",
       "      <td>Repeat: Davis Bennett discussed the importance...</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474953</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Some common topics of humor and criticism abou...</td>\n",
       "      <td>[Mark Kittisopikul said: I will await your upd...</td>\n",
       "      <td>Science has developed internal tools such as m...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.341040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>Science has developed a *ton* of internal tool...</td>\n",
       "      <td>[William Katz said: https://twitter.com/maxhod...</td>\n",
       "      <td>The office hours for this week are scheduled f...</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.313135</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What are this week's office hour timings, as c...</td>\n",
       "      <td>Srini's office hours will begin next week on T...</td>\n",
       "      <td>[William Katz said:  I propose we start this w...</td>\n",
       "      <td>The office hours with Srini Turaga are schedul...</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.761365</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Here's the question:\\n\\n\"What are the proposed...</td>\n",
       "      <td>The proposed office hour arrangements are Srin...</td>\n",
       "      <td>[William Katz said:  I propose we start this w...</td>\n",
       "      <td>Davis Bennett suggests improving the h5py API ...</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569172</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Davis Bennett suggests that the h5py API shoul...</td>\n",
       "      <td>[Davis Bennett said: loving these filenames in...</td>\n",
       "      <td>Gert-Jan Both made changes to the API of xray ...</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.581201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Gert-Jan Both made some changes to the API of ...</td>\n",
       "      <td>[Gert-Jan Both said: Welcome everyone! As you ...</td>\n",
       "      <td>The purpose of the QZ decomposition in this ma...</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566109</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The purpose of the QZ decomposition in this ma...</td>\n",
       "      <td>[.10534273, -0.5556871 ,\\n         0.8352932 ,...</td>\n",
       "      <td>Cristian Goina does not run his code with the ...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The kernel crashes</td>\n",
       "      <td>[.        ,  0.        ,  0.        ,  0.     ...</td>\n",
       "      <td>Docker containers require sudo privileges to b...</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641116</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What are the main differences between Docker a...</td>\n",
       "      <td>The main differences between Docker and Singul...</td>\n",
       "      <td>[Robert Lines said: The biggest gotcha we have...</td>\n",
       "      <td>The course pace involves meetings every other ...</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793306</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The proposed pace of the course is to have a v...</td>\n",
       "      <td>[William Katz said:  I propose we start this w...</td>\n",
       "      <td>To attach VSCode to a bsub session for debuggi...</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408650</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>To attach VSCode to a bsub session for debuggi...</td>\n",
       "      <td>[Eric Wait said: Has anyone attached VScode to...</td>\n",
       "      <td>Davis Bennett's concern with h5py is its tende...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519172</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Python 3.10.6</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>Konrad Rokicki's explanation and Robert Lines'...</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585413</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>Davis Bennett's complaint about h5py is that i...</td>\n",
       "      <td>[Davis Bennett said: loving these filenames in...</td>\n",
       "      <td>Robert Lines and Konrad Rokicki balance memory...</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Here's a rewritten question that requires mult...</td>\n",
       "      <td>Konrad Rokicki's explanation reveals that by d...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>The autogenerated filenames in the h5py source...</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480277</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Here's a rewritten question that conveys the s...</td>\n",
       "      <td>Robert Lines and Konrad Rokicki balance memory...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>Potential causes for issues with running tasks...</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484702</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The autogenerated filenames in the h5py source...</td>\n",
       "      <td>[Davis Bennett said: loving these filenames in...</td>\n",
       "      <td>The absence of a direct method to close datase...</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.617290</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The issue with running tasks on workers in a d...</td>\n",
       "      <td>[ in get\\n      results = self.gather(packed, ...</td>\n",
       "      <td>The issue of not being able to remove intermed...</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.596358</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>h5py doesn't provide a straightforward way to ...</td>\n",
       "      <td>[ the big headaches when trying to use h5py wi...</td>\n",
       "      <td>The issue with running tasks in the distribute...</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457028</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The issue of not being able to remove intermed...</td>\n",
       "      <td>[Greg Fleishman said: Is anyone aware of any c...</td>\n",
       "      <td>Translation and conversion approaches face lim...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.539139</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The issue might be caused by a version mismatc...</td>\n",
       "      <td>[ in get\\n      results = self.gather(packed, ...</td>\n",
       "      <td>To attach VScode to an interactive bsub sessio...</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576444</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The limitations of translation and conversion ...</td>\n",
       "      <td>[William Katz said: https://www.biorxiv.org/co...</td>\n",
       "      <td>Docker containers typically require sudo privi...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480726</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>To attach VScode to an interactive bsub sessio...</td>\n",
       "      <td>[Eric Wait said: Has anyone attached VScode to...</td>\n",
       "      <td>Mamba is faster than Conda.</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567529</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>What is the main difference between Docker and...</td>\n",
       "      <td>The main difference between Docker and Singula...</td>\n",
       "      <td>[Robert Lines said: The biggest gotcha we have...</td>\n",
       "      <td>Nextflow's current approach to memory manageme...</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606333</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Here is a rewritten version of the question:\\n...</td>\n",
       "      <td>The answer to given question can be inferred f...</td>\n",
       "      <td>[Mary Lay said: Best way to set up mamba when ...</td>\n",
       "      <td>The `warp` command in Interpolations.jl produc...</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541326</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Nextflow's current approach to memory manageme...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>The schedule of the How To interest group meet...</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The `warp` command in Interpolations.jl produc...</td>\n",
       "      <td>[ points are handled - pass img as an\\n  Abst...</td>\n",
       "      <td>Davis Bennett's complaint about h5py is relate...</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.510864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The How To interest group meetings will move t...</td>\n",
       "      <td>[Mark Kittisopikul said: We are moving How To ...</td>\n",
       "      <td>The `chromatix` package was updated to include...</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.548583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>Davis Bennett's complaint is that h5py hangs o...</td>\n",
       "      <td>[Davis Bennett said: loving these filenames in...</td>\n",
       "      <td>The purpose of extending the OME-NGFF open for...</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The changes made to the chromatic package rega...</td>\n",
       "      <td>[_ramps`) now return phase directly as `ndarra...</td>\n",
       "      <td>Luca Marconato is presenting at tomorrow's sem...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627679</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>What is the main difference between Docker and...</td>\n",
       "      <td>The context does not mention Docker or Singula...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>The proposed chunk index includes an additiona...</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>To address challenges created by heterogeneity...</td>\n",
       "      <td>[Mark Kittisopikul said: \\nHello *&lt;!channel&gt;*,...</td>\n",
       "      <td>The proposed chunk index in the ZEP2 spec diff...</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.557922</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>The presenter is Luca Marconato, and the focus...</td>\n",
       "      <td>[Mark Kittisopikul said: \\nHello *&lt;!channel&gt;*,...</td>\n",
       "      <td>Yann Collet's hobby of creating a game for his...</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510281</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>The main differences between the proposed chun...</td>\n",
       "      <td>[Mark Kittisopikul said: I posted a comparison...</td>\n",
       "      <td>Davis Bennett discussed the importance of vect...</td>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The main differences between the proposed chun...</td>\n",
       "      <td>[Mark Kittisopikul said: I posted a comparison...</td>\n",
       "      <td>Translation and conversion approaches face lim...</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Yann was bored and working as a project manage...</td>\n",
       "      <td>[William Katz said: https://corecursive.com/da...</td>\n",
       "      <td>NGFF addresses limitations in accessing bioima...</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823630</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Some common topics of humor and criticism rega...</td>\n",
       "      <td>[Mark Kittisopikul said: I will await your upd...</td>\n",
       "      <td>Eric Wait's experience with building FicTrac f...</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557039</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The limitations of translation and conversion ...</td>\n",
       "      <td>[William Katz said: https://www.biorxiv.org/co...</td>\n",
       "      <td>The purpose of the talk about cataloging versi...</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.532606</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Here's a rewritten question that meets the rul...</td>\n",
       "      <td>OME-NGFF introduces next-generation file forma...</td>\n",
       "      <td>[William Katz said: https://www.biorxiv.org/co...</td>\n",
       "      <td>Introducing a child to Lego robotics at the ag...</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551096</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The differences in building FicTrac using diff...</td>\n",
       "      <td>[Davis Bennett said: Eric Wait you were recomm...</td>\n",
       "      <td>Yann Collet's interest in data compression was...</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492466</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Davis Bennett said that the talk about catalog...</td>\n",
       "      <td>[Davis Bennett said: reminder:  today at 2:45 ...</td>\n",
       "      <td>Yann Collet, a former project manager, transit...</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506962</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>Lego robotics was introduced as an interesting...</td>\n",
       "      <td>[Philip Hubbard said: My twins are in kinderga...</td>\n",
       "      <td>The purpose of the `@multimethod` macro in Jul...</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Yann was bored and working as a project manage...</td>\n",
       "      <td>[William Katz said: https://corecursive.com/da...</td>\n",
       "      <td>The proposed chunk index involves an extra 4-b...</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509726</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Yann was bored and working as a project manage...</td>\n",
       "      <td>[William Katz said: https://corecursive.com/da...</td>\n",
       "      <td>Julia's method for identifying anonymous varia...</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593124</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Based on the given context, a suitable questio...</td>\n",
       "      <td>The purpose of the `@multimethod` macro in Jul...</td>\n",
       "      <td>[               \"argument must be a block\")\\n ...</td>\n",
       "      <td>Davis Bennett's concern is related to how h5py...</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454208</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The main differences between the proposed chun...</td>\n",
       "      <td>[Mark Kittisopikul said: I posted a comparison...</td>\n",
       "      <td>Running daemon services inside Singularity con...</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.534322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What's Julia's way to identify anonymous varia...</td>\n",
       "      <td>The answer is present in context, specifically...</td>\n",
       "      <td>[               \"argument must be a block\")\\n ...</td>\n",
       "      <td>Juno's suitability for simulating optical syst...</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Davis Bennett's complaint is that h5py hangs o...</td>\n",
       "      <td>[Davis Bennett said: loving these filenames in...</td>\n",
       "      <td>To attach VSCode to a bsub session for debuggi...</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some of the challenges and differences when ru...</td>\n",
       "      <td>[Robert Lines said: The biggest gotcha we have...</td>\n",
       "      <td>The spread of COVID-19 among attendees at SIGG...</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460099</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Here is the rewritten question:\\n\\n\"What makes...</td>\n",
       "      <td>Juno is suitable for simulating optical system...</td>\n",
       "      <td>[Srini said: https://twitter.com/mariescopy/st...</td>\n",
       "      <td>Gert-Jan Both points out the potential issue o...</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>To attach VSCode to a bsub session for debuggi...</td>\n",
       "      <td>[Eric Wait said: Has anyone attached VScode to...</td>\n",
       "      <td>There is no mention of Davis Bennett or any di...</td>\n",
       "      <td>78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.540843</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>The factors that contributed to the spread of ...</td>\n",
       "      <td>[William Katz said: Some interesting data from...</td>\n",
       "      <td>To expand the current single-user setup to sup...</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527815</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>Gert-Jan Both highlights that using asserts in...</td>\n",
       "      <td>[\\n Examples and tests still need to be updat...</td>\n",
       "      <td>Mark Kittisopikul's information does not menti...</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Developers face challenges such as a complete ...</td>\n",
       "      <td>[Davis Bennett said: can anyone make sense of ...</td>\n",
       "      <td>Hannah encountered syntax challenges with CMak...</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661283</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>You should be able to automatically create the...</td>\n",
       "      <td>[David Ackerman said: I can now run a sample d...</td>\n",
       "      <td>The Julia construct that enables multimethod d...</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692545</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>According to Mark Kittisopikul, common feature...</td>\n",
       "      <td>[Mark Kittisopikul said: I've seen Synology us...</td>\n",
       "      <td>SSH connection issues can arise due to various...</td>\n",
       "      <td>83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527518</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>What challenges did Hannah face building FicTr...</td>\n",
       "      <td>Hannah faced challenges with building FicTrac ...</td>\n",
       "      <td>[Davis Bennett said: Eric Wait you were recomm...</td>\n",
       "      <td>Cristian Goina's suspicion that a version mism...</td>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Here's a rewritten question that combines info...</td>\n",
       "      <td>Multimethod dispatch in Julia enables multimet...</td>\n",
       "      <td>[               \"argument must be a block\")\\n ...</td>\n",
       "      <td>The HDF5 fixed array data block and the propos...</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.487407</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>What causes SSH connection issues, and how doe...</td>\n",
       "      <td>The `login1` ssh host key has changed recently...</td>\n",
       "      <td>[Stuart Berg said: Robert Lines Ken Carlile Ha...</td>\n",
       "      <td>The changes made to the chromatix elements and...</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The issue with running tasks on workers in the...</td>\n",
       "      <td>[ in get\\n      results = self.gather(packed, ...</td>\n",
       "      <td>Davis Bennett mentions Arraylake in the contex...</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The main differences between the HDF5 fixed ar...</td>\n",
       "      <td>[Mark Kittisopikul said: Numcodecs is in urgen...</td>\n",
       "      <td>Juno, a Python-based graphical package for opt...</td>\n",
       "      <td>88</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The following changes were made to the chromat...</td>\n",
       "      <td>[_ramps`) now return phase directly as `ndarra...</td>\n",
       "      <td>To reduce maintenance efforts, some features a...</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.684598</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Arraylake is a data lake platform for managing...</td>\n",
       "      <td>[Davis Bennett said: reminder:  today at 2:45 ...</td>\n",
       "      <td>Sequential storage in highly parallel data ser...</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547317</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Based on the given context, a question that ca...</td>\n",
       "      <td>Juno allows users to design and visualise arbi...</td>\n",
       "      <td>[Srini said: https://twitter.com/mariescopy/st...</td>\n",
       "      <td>Mark Kittisopikul mentioned that the reason fo...</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The reason for sending some features upstream ...</td>\n",
       "      <td>[Mark Kittisopikul said: https://root.cern/blo...</td>\n",
       "      <td>The key differences between the FastAI approac...</td>\n",
       "      <td>92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541482</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Sequential storage (i.e., trying to maximize a...</td>\n",
       "      <td>[William Katz said: Some links from my second ...</td>\n",
       "      <td>The limitations that led K-Optional Software t...</td>\n",
       "      <td>93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549754</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>According to Mark Kittisopikul, the reason for...</td>\n",
       "      <td>[Mark Kittisopikul said: Numcodecs is in urgen...</td>\n",
       "      <td>The current approach to setting memory limits ...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500086</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Based on the given context, a suitable questio...</td>\n",
       "      <td>nan</td>\n",
       "      <td>[Philip Hubbard said: FastAI supports \"augment...</td>\n",
       "      <td>The common hosting solution used by many libra...</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587268</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The limitations that led K-Optional Software t...</td>\n",
       "      <td>[William Katz said: Recent blog post on why a ...</td>\n",
       "      <td>Some potential challenges or requirements for ...</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792849</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>According to Robert Lines, the current approac...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>The RSA host key for the `login1` SSH host has...</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Discourse is a common hosting solution used by...</td>\n",
       "      <td>[Habib Bukhari said: Or just use our own host....</td>\n",
       "      <td>The four main steps are Data Ingestion, Point-...</td>\n",
       "      <td>98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.427849</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some potential challenges or requirements for ...</td>\n",
       "      <td>[Habib Bukhari said: Or just use our own host....</td>\n",
       "      <td>Davis Bennett suggests exposing a __exit__() m...</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563206</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The test is checking the accuracy of the GGESE...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The 7000 series train cars used by Mark Kittis...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385759</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The RSA host key for login1 has changed</td>\n",
       "      <td>[Stuart Berg said: Robert Lines Ken Carlile Ha...</td>\n",
       "      <td>You will be given parking instructions at the ...</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596746</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The four main steps involved in aligning overl...</td>\n",
       "      <td>[Alignment Guide\\nTitle: Alignment Guide\\nAuth...</td>\n",
       "      <td>The `@multimethod` macro in Julia programming ...</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Davis Bennett suggests exposing a __exit__() m...</td>\n",
       "      <td>[Davis Bennett said: loving these filenames in...</td>\n",
       "      <td>The purpose of hosting a virtual N5 file via a...</td>\n",
       "      <td>103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600621</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The 7000 series train cars used by Mark Kittis...</td>\n",
       "      <td>[-get-more-frequent-rail-service.cfm\\nMark Kit...</td>\n",
       "      <td>Developers often encounter difficulties when u...</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532625</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>According to Mark Kittisopikul, there are no o...</td>\n",
       "      <td>[Mark Kittisopikul said: Grabbed some photos o...</td>\n",
       "      <td>Mark Kittisopikul's meeting with HDF Group is ...</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The @multimethod macro is used to define multi...</td>\n",
       "      <td>[               \"argument must be a block\")\\n ...</td>\n",
       "      <td>Nextflow jobs are not terminated by the OOM ki...</td>\n",
       "      <td>106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493289</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The purpose of hosting a \"virtual\" N5 file via...</td>\n",
       "      <td>[Stuart Berg said: Marwan Zouinkhi In the thre...</td>\n",
       "      <td>Nextflow has the capability to retry jobs with...</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Here's a rewritten question that conveys the s...</td>\n",
       "      <td>Developers typically encounter challenges when...</td>\n",
       "      <td>[Davis Bennett said: can anyone make sense of ...</td>\n",
       "      <td>The purpose of Don Olbris' introduction-demons...</td>\n",
       "      <td>108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482208</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The scheduled call time for Mark Kittisopikul'...</td>\n",
       "      <td>[Mark Kittisopikul said: Is there anyone else ...</td>\n",
       "      <td>The primary functions of the SAGE imagery inde...</td>\n",
       "      <td>109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480373</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>The retry mechanism in Nextflow prevents jobs ...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>Gert-Jan Both highlights potential issues or c...</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527792</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Nextflow can retry jobs with more memory, as m...</td>\n",
       "      <td>[Konrad Rokicki said: Robert Lines I was wrong...</td>\n",
       "      <td>The solving environment time when creating con...</td>\n",
       "      <td>111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose was to introduce and demonstrate t...</td>\n",
       "      <td>[WikiTalkSept2006\\nTitle: WikiTalkSept2006\\nAu...</td>\n",
       "      <td>Disconnecting from the VPN resolves Philip Hub...</td>\n",
       "      <td>112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.597411</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The primary functions of the SAGE imagery inde...</td>\n",
       "      <td>[SAGE imagery indexer\\nTitle: SAGE imagery ind...</td>\n",
       "      <td>The tool used for exploring matches on the das...</td>\n",
       "      <td>113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558433</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some potential issues or considerations when u...</td>\n",
       "      <td>[\\n Examples and tests still need to be updat...</td>\n",
       "      <td>Go is an open source programming language.</td>\n",
       "      <td>114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.657085</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Mamba ended up taking maybe 2 min. Conda took ...</td>\n",
       "      <td>[Mary Lay said: Best way to set up mamba when ...</td>\n",
       "      <td>The tentative schedule for the call with HDF G...</td>\n",
       "      <td>115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.470692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>What's the solution for Philip Hubbard's probl...</td>\n",
       "      <td>Philip Hubbard's solution for the problem with...</td>\n",
       "      <td>[Philip Hubbard said: Does anyone else have tr...</td>\n",
       "      <td>The purpose of the call arranged by HDF Group ...</td>\n",
       "      <td>116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571664</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>What's used for exploring matches on the dashb...</td>\n",
       "      <td>To view and navigate tile collections in the R...</td>\n",
       "      <td>[\\napproximation as a rough alignment. The rig...</td>\n",
       "      <td>The `shared_buffers` setting in PostgreSQL sho...</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Go is an open source programming language that...</td>\n",
       "      <td>[Mark Kittisopikul said: Go 1.18 gets generics...</td>\n",
       "      <td>Extrapolating on polling, they estimate 2000 o...</td>\n",
       "      <td>118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The tentative schedule for the call with HDF G...</td>\n",
       "      <td>[Mark Kittisopikul said: Is there anyone else ...</td>\n",
       "      <td>The SAGE imagery indexer will extract the foll...</td>\n",
       "      <td>119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487891</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The purpose of the call is to allow participan...</td>\n",
       "      <td>[Mark Kittisopikul said: Is there anyone else ...</td>\n",
       "      <td>Philip Hubbard discusses the key differences b...</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>What percentage of RAM should the `shared_buff...</td>\n",
       "      <td>1/4 to 1/3 of RAM</td>\n",
       "      <td>[PostgreSQL Performance Tuning\\nTitle: Postgre...</td>\n",
       "      <td>K-Optional Software decided to move away from ...</td>\n",
       "      <td>121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>According to William Katz, the estimated numbe...</td>\n",
       "      <td>[William Katz said: Some interesting data from...</td>\n",
       "      <td>To qualify for free forum hosting from Discour...</td>\n",
       "      <td>122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The SAGE imagery indexer will extract informat...</td>\n",
       "      <td>[SAGE imagery indexer\\nTitle: SAGE imagery ind...</td>\n",
       "      <td>How can you engage a young child in a strategi...</td>\n",
       "      <td>123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481732</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Based on the given context, a suitable questio...</td>\n",
       "      <td>The key differences between the FastAI approac...</td>\n",
       "      <td>[Philip Hubbard said: FastAI supports \"augment...</td>\n",
       "      <td>Using 'perturbations' in FastAI's `DataBlock` ...</td>\n",
       "      <td>124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The limitations that led K-Optional Software t...</td>\n",
       "      <td>[William Katz said: Recent blog post on why a ...</td>\n",
       "      <td>Optimize PostgreSQL performance for database o...</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550620</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>What are the conditions that need to be met in...</td>\n",
       "      <td>The conditions that need to be met in order to...</td>\n",
       "      <td>[Habib Bukhari said: Or just use our own host....</td>\n",
       "      <td>The code snippet, when closing objects, ensure...</td>\n",
       "      <td>126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503558</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Here is a rewritten question that conveys the ...</td>\n",
       "      <td>Introducing chess by playing with general rule...</td>\n",
       "      <td>[Philip Hubbard said: My twins are in kinderga...</td>\n",
       "      <td>The Viewer class adjusts the camera position b...</td>\n",
       "      <td>127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452834</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The answer to given question is present in con...</td>\n",
       "      <td>[Philip Hubbard said: FastAI supports \"augment...</td>\n",
       "      <td>Setting the `pixelRatio` and `setSize` methods...</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>How can PostgreSQL performance be optimized fo...</td>\n",
       "      <td>Configuration settings for PostgreSQL performa...</td>\n",
       "      <td>[PostgreSQL Performance Tuning\\nTitle: Postgre...</td>\n",
       "      <td>The focus of the first Code Review Interest Gr...</td>\n",
       "      <td>129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513215</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>The code snippet closes objects. It first call...</td>\n",
       "      <td>[            self.id._close_open_objects(h5f.O...</td>\n",
       "      <td>The camera's position plays a vital role in de...</td>\n",
       "      <td>130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525256</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>What changes does the Viewer class make to sup...</td>\n",
       "      <td>The Viewer class makes several changes to supp...</td>\n",
       "      <td>[ // \"RedFormat\" is not documented, but used h...</td>\n",
       "      <td>The purpose of the ray marching iterations in ...</td>\n",
       "      <td>131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.656899</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>According to Mark Kittisopikul, common feature...</td>\n",
       "      <td>[Mark Kittisopikul said: I've seen Synology us...</td>\n",
       "      <td>The purpose of the change in indexing after ro...</td>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547765</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of setting the `pixelRatio` and `s...</td>\n",
       "      <td>[     this.renderer.setClearColor(\"#000000\")\\n...</td>\n",
       "      <td>React uses an explicit top-down data flow appr...</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536086</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The focus of the first Code Review Interest Gr...</td>\n",
       "      <td>[William Katz said: The next two Code Review I...</td>\n",
       "      <td>The purpose of the 'Introduction to the Wiki' ...</td>\n",
       "      <td>134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655299</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>What is the significance of the camera's posit...</td>\n",
       "      <td>The camera's position is significant in determ...</td>\n",
       "      <td>[, this.camera)\\n        // Updated, for camer...</td>\n",
       "      <td>The purpose of setting `this.clipFillingPlane....</td>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734711</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the ray marching iterations is ...</td>\n",
       "      <td>[ length is just delta.\\n      float deltaDire...</td>\n",
       "      <td>The `singularity run` command in AlphaFold is ...</td>\n",
       "      <td>136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525309</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the change in indexing after ro...</td>\n",
       "      <td>[Davis Bennett said: after rotation of the `[1...</td>\n",
       "      <td>Common issues with network file system permiss...</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>React uses an explicit top-down data flow, wit...</td>\n",
       "      <td>[, this.camera)\\n        // Updated, for camer...</td>\n",
       "      <td>The purpose of the two Code Review Interest Gr...</td>\n",
       "      <td>138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.513454</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>During warping, values for img must be reconst...</td>\n",
       "      <td>[Davis Bennett said: after rotation of the `[1...</td>\n",
       "      <td>The purpose of the UniClust30_database_path in...</td>\n",
       "      <td>139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The purpose of the 'Introduction to the Wiki' ...</td>\n",
       "      <td>[WikiTalkSept2006\\nTitle: WikiTalkSept2006\\nAu...</td>\n",
       "      <td>You will be given parking instructions at the ...</td>\n",
       "      <td>140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480758</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of setting this.clipFillingPlane.v...</td>\n",
       "      <td>[.src = canvas.toDataURL()\\n        img.style....</td>\n",
       "      <td>The main difference between Akaike Information...</td>\n",
       "      <td>141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452865</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>This command is used to get help and diagnosti...</td>\n",
       "      <td>[Alphafold\\nTitle: Alphafold\\nAuthors: Goran C...</td>\n",
       "      <td>The steps to generate and align image metadata...</td>\n",
       "      <td>142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.572534</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>nan</td>\n",
       "      <td>[ mount the storage\\n\\n  * Is the computer is ...</td>\n",
       "      <td>The key settings used to generate and configur...</td>\n",
       "      <td>143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the two Code Review Interest Gr...</td>\n",
       "      <td>[William Katz said: The next two Code Review I...</td>\n",
       "      <td>Transferring data between the CPU and the GPU ...</td>\n",
       "      <td>144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The UniClust30_database_path provides a refere...</td>\n",
       "      <td>[uniref90/uniref90.fasta \\\\n    --mgnify_datab...</td>\n",
       "      <td>Translation and conversion approaches face lim...</td>\n",
       "      <td>145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541880</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>According to the context, there are no overnig...</td>\n",
       "      <td>[Mark Kittisopikul said: Grabbed some photos o...</td>\n",
       "      <td>The sequence file contains the FASTA paths of ...</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The main difference between Akaike Information...</td>\n",
       "      <td>[Mark Kittisopikul said: Greg Fleishman, I was...</td>\n",
       "      <td>Cling's use of LLVM 5 is considered an issue a...</td>\n",
       "      <td>147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>The steps involved in generating and aligning ...</td>\n",
       "      <td>[ process.  \\n  \\n\\n    2. Create a render sta...</td>\n",
       "      <td>Synology NAS devices offer features such as ce...</td>\n",
       "      <td>148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510332</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The key settings used to generate and configur...</td>\n",
       "      <td>[    }\\n      componentWillUnmount() {\\n      ...</td>\n",
       "      <td>The proposed chunk index and HDF5 fixed array ...</td>\n",
       "      <td>149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some of the challenges when using h5py with di...</td>\n",
       "      <td>[ the big headaches when trying to use h5py wi...</td>\n",
       "      <td>To set up and run a spark process using `rende...</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603210</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The limitations of translation and conversion ...</td>\n",
       "      <td>[William Katz said: https://www.biorxiv.org/co...</td>\n",
       "      <td>To manage share access for SciComp OU groups, ...</td>\n",
       "      <td>151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508178</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The sequence file contains the FASTA paths of ...</td>\n",
       "      <td>[Alphafold\\nTitle: Alphafold\\nAuthors: Goran C...</td>\n",
       "      <td>The potential challenge in applying `Dask.arra...</td>\n",
       "      <td>152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548645</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The issue with Cling's use of LLVM is that it ...</td>\n",
       "      <td>[Mark Kittisopikul said: https://root.cern/blo...</td>\n",
       "      <td>Flipping the depth test when rendering the cli...</td>\n",
       "      <td>153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547925</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>What changes does the Viewer class make to sup...</td>\n",
       "      <td>The Viewer class supports a camera that has mo...</td>\n",
       "      <td>[ // \"RedFormat\" is not documented, but used h...</td>\n",
       "      <td>The tile pair generation in the alignment proc...</td>\n",
       "      <td>154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Synology Inc. centralizes data storage and bac...</td>\n",
       "      <td>[Mark Kittisopikul said: I've seen Synology us...</td>\n",
       "      <td>React's typical approach involves using event ...</td>\n",
       "      <td>155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403231</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Here's a possible rewritten version:\\n\\n\"What ...</td>\n",
       "      <td>The main differences between the proposed chun...</td>\n",
       "      <td>[Mark Kittisopikul said: I posted a comparison...</td>\n",
       "      <td>The main app component of the SCA 3D Graphics ...</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542191</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Here's a rewritten question that meets the rul...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[rootDirectory /nrs/flyem/render/scapes/khairy...</td>\n",
       "      <td>The sweet spot between model simplicity and fi...</td>\n",
       "      <td>157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467097</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>To manage share access for SciComp OU groups, ...</td>\n",
       "      <td>[Troubleshooting common Janelia Shared Storage...</td>\n",
       "      <td>Docker containers require sudo privileges to b...</td>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>The key challenge when applying Dask.array.coa...</td>\n",
       "      <td>[Davis Bennett said: if anyone needs to make n...</td>\n",
       "      <td>To balance conflicting events with our regular...</td>\n",
       "      <td>159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439208</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>Flipping the depth test when rendering the cli...</td>\n",
       "      <td>[.src = canvas.toDataURL()\\n        img.style....</td>\n",
       "      <td>Store immutable images like registered graysca...</td>\n",
       "      <td>160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.422628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>What drives tile pair generation in the alignm...</td>\n",
       "      <td>Tile pair generation in the alignment process ...</td>\n",
       "      <td>[ are intensity based (due to the lower\\nresol...</td>\n",
       "      <td>The `warp` command in Julia transforms an inpu...</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>React's approach to handling mouse events in c...</td>\n",
       "      <td>[, this.camera)\\n        // Updated, for camer...</td>\n",
       "      <td>The agenda for the meeting scheduled by HDF Gr...</td>\n",
       "      <td>162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420886</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Here's a possible rewritten version:\\n\\n\"What ...</td>\n",
       "      <td>The main app component loads volume data into ...</td>\n",
       "      <td>[SCA 3D Graphics Solution: Direct Volume Rende...</td>\n",
       "      <td>The code snippet in its `createTestTexture` fu...</td>\n",
       "      <td>163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503343</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>What's the sweet spot between model simplicity...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[Mark Kittisopikul said: Sometimes the simplic...</td>\n",
       "      <td>Docker containers require sudo privileges to b...</td>\n",
       "      <td>164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.582231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>What is the main difference between Docker and...</td>\n",
       "      <td>Docker containers expect you to enter as root ...</td>\n",
       "      <td>[Robert Lines said: The biggest gotcha we have...</td>\n",
       "      <td>When test data is activated, the workaround fo...</td>\n",
       "      <td>165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.579978</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The answer to given question is present in con...</td>\n",
       "      <td>[Mark Kittisopikul said: We are moving How To ...</td>\n",
       "      <td>Diffrax updates could potentially influence th...</td>\n",
       "      <td>166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504691</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The recommended approach for storing immutable...</td>\n",
       "      <td>[William Katz said: Konrad Rokicki Davis Benne...</td>\n",
       "      <td>The purpose of adding items to the Need Post P...</td>\n",
       "      <td>167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.564241</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The `warp` command in Julia produces an output...</td>\n",
       "      <td>[ points are handled - pass img as an\\n  Abst...</td>\n",
       "      <td>To configure a new website for the database in...</td>\n",
       "      <td>168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532581</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>The agenda has not been set, but it's more abo...</td>\n",
       "      <td>[Mark Kittisopikul said: Is there anyone else ...</td>\n",
       "      <td>The file permission issue when trying to remov...</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The code snippet generates a test texture for ...</td>\n",
       "      <td>[ data.byteLength + \" bytes, converted \" + dat...</td>\n",
       "      <td>Clone the simple Java Spark project, ensure Ma...</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615981</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>What is the main difference between Docker and...</td>\n",
       "      <td>The main difference between Docker and Singula...</td>\n",
       "      <td>[Robert Lines said: The biggest gotcha we have...</td>\n",
       "      <td>The SAGE imagery indexer will extract the foll...</td>\n",
       "      <td>171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540919</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>When test data kicks in, there is an initial r...</td>\n",
       "      <td>[ data.byteLength + \" bytes, converted \" + dat...</td>\n",
       "      <td>Enabling test data replaces medical or neuron ...</td>\n",
       "      <td>172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[Philip Hubbard said: FastAI supports \"augment...</td>\n",
       "      <td>It is not currently possible to create a Gauss...</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of adding items to the 'Need Post ...</td>\n",
       "      <td>[63x-left_dorsal. Adding to folder Need Post P...</td>\n",
       "      <td>For performing diagnostics on image stacks usi...</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604758</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>NEW_WEBSITE_NAME, dbi, DBI_STRING, username, U...</td>\n",
       "      <td>[ the lines have been loaded previously\\n\\n###...</td>\n",
       "      <td>Juno is a complete library with a graphical us...</td>\n",
       "      <td>175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420323</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The file permission issue might have been caus...</td>\n",
       "      <td>[Greg Fleishman said: Is anyone aware of any c...</td>\n",
       "      <td>The two image alignment pipelines discussed in...</td>\n",
       "      <td>176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526680</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>To create a mini-stack using the spark process...</td>\n",
       "      <td>[rootDirectory /nrs/flyem/render/scapes/khairy...</td>\n",
       "      <td>The steps involved in uploading imagery for Ne...</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668446</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The system will extract information from the i...</td>\n",
       "      <td>[SAGE imagery indexer\\nTitle: SAGE imagery ind...</td>\n",
       "      <td>To synchronize publication decisions with SAGE...</td>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580650</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>When you enable test data, it triggers an extr...</td>\n",
       "      <td>[ data.byteLength + \" bytes, converted \" + dat...</td>\n",
       "      <td>Adjust the `checkpoint_segments` parameter to ...</td>\n",
       "      <td>179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>It is not currently possible to create a Gauss...</td>\n",
       "      <td>[Davis Bennett said: if anyone needs to make n...</td>\n",
       "      <td>The key differences between ZEP2 chunk index a...</td>\n",
       "      <td>180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528933</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[Mark Kittisopikul said: I will await your upd...</td>\n",
       "      <td>When deciding whether to use Rust at a startup...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592670</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some examples of how to perform diagnostics on...</td>\n",
       "      <td>[ full alignment solve. The following are some...</td>\n",
       "      <td>The purpose of the Talk Science with SciComp S...</td>\n",
       "      <td>182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.534960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Juno is a Python-based graphical package for o...</td>\n",
       "      <td>[Srini said: https://twitter.com/mariescopy/st...</td>\n",
       "      <td>The purpose of the Talk Science with SciComp S...</td>\n",
       "      <td>183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.572198</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The two image alignment pipelines discussed in...</td>\n",
       "      <td>[\\napproximation as a rough alignment. The rig...</td>\n",
       "      <td>When troubleshooting issues with accessing sha...</td>\n",
       "      <td>184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487650</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The steps involved in uploading imagery for Ne...</td>\n",
       "      <td>[Uploading imagery for NeuronBridge\\nTitle: Up...</td>\n",
       "      <td>The recommended way to close open objects rela...</td>\n",
       "      <td>185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Here's a rewritten question that requires mult...</td>\n",
       "      <td>To synchronize publication decisions with SAGE...</td>\n",
       "      <td>[How to Synchronize Publication Decisions to S...</td>\n",
       "      <td>The different options available to run the Sag...</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.596426</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>To balance performance for heavy write scenari...</td>\n",
       "      <td>[PostgreSQL Performance Tuning\\nTitle: Postgre...</td>\n",
       "      <td>An environment variable named \"CONFIG_SERVER_U...</td>\n",
       "      <td>187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400913</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Here's a rewritten question that requires mult...</td>\n",
       "      <td>The main differences between ZEP2 chunk index ...</td>\n",
       "      <td>[Mark Kittisopikul said: I posted a comparison...</td>\n",
       "      <td>Some challenges and limitations associated wit...</td>\n",
       "      <td>188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Here's the question that can be fully answered...</td>\n",
       "      <td>Rust isn't the best choice if your app needs a...</td>\n",
       "      <td>[William Katz said: tl;dr: Rust is good at som...</td>\n",
       "      <td>The test is checking if the result of the GGE ...</td>\n",
       "      <td>189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Science team leads are invited to discuss thei...</td>\n",
       "      <td>[Talk Science with SciComp Software\\nTitle: Ta...</td>\n",
       "      <td>The parameters that can be used in sage_json.p...</td>\n",
       "      <td>190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535643</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Science team leads are invited to discuss thei...</td>\n",
       "      <td>[Talk Science with SciComp Software\\nTitle: Ta...</td>\n",
       "      <td>The typical workflow for uploading searchable ...</td>\n",
       "      <td>191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599437</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>When troubleshooting issues with accessing sha...</td>\n",
       "      <td>[ (devfs, local, nobrowse)\\n        /dev/disk3...</td>\n",
       "      <td>The proposed solution for addressing file form...</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850715</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The recommended way to close open objects rela...</td>\n",
       "      <td>[ the big headaches when trying to use h5py wi...</td>\n",
       "      <td>Factors to consider when evaluating the comple...</td>\n",
       "      <td>193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629434</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The different options available to run the Sag...</td>\n",
       "      <td>[Sage-based External Website Cross-loader\\nTit...</td>\n",
       "      <td>The `MAX_STEPS` variable in ray marching deter...</td>\n",
       "      <td>194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460897</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The necessary environment variables and JWT to...</td>\n",
       "      <td>[Uploading imagery for NeuronBridge\\nTitle: Up...</td>\n",
       "      <td>The challenges and difficulties encountered wh...</td>\n",
       "      <td>195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407593</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The challenges and limitations associated with...</td>\n",
       "      <td>[Flattening\\nTitle: Flattening\\nAuthors: Unkno...</td>\n",
       "      <td>Synology is not mentioned in the provided cont...</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478798</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The test is checking if the result of the GGE ...</td>\n",
       "      <td>[e-01,... 0.36549678, 0.9152956 ,\\n       1.01...</td>\n",
       "      <td>The key evaluation criteria for choosing a bac...</td>\n",
       "      <td>197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>What parameters can be used in sage_json.php, ...</td>\n",
       "      <td>The parameters that can be used in sage_json.p...</td>\n",
       "      <td>[SAGE Ajax\\nTitle: SAGE Ajax\\nAuthors: Rob Svi...</td>\n",
       "      <td>What key considerations should you prioritize ...</td>\n",
       "      <td>198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.568551</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Here's a rewritten question that requires mult...</td>\n",
       "      <td>The typical workflow for uploading searchable ...</td>\n",
       "      <td>[-flylight-color-depth\\n\\nThe code you'll need...</td>\n",
       "      <td>To restart an NX NoMachine session on a Login ...</td>\n",
       "      <td>199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.513454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Here's a rewritten version that requires multi...</td>\n",
       "      <td>The proposed fix for file format heterogeneity...</td>\n",
       "      <td>[Mark Kittisopikul said: \\nHello *&lt;!channel&gt;*,...</td>\n",
       "      <td>Data access approaches directly impact analysi...</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Here's a question that can be fully answered f...   \n",
       "1    Here is a question that can be fully answered ...   \n",
       "2    Here's a rewritten version of the question:\\n\\...   \n",
       "3    Here's the question that can be fully answered...   \n",
       "4    Here's a question that can be fully answered f...   \n",
       "5    Here's a rewritten question that conveys the s...   \n",
       "6    Here is a question that can be fully answered ...   \n",
       "7    Here is a question that can be fully answered ...   \n",
       "8    Here is a question that can be fully answered ...   \n",
       "9    Here's the question that can be fully answered...   \n",
       "10   Here is a question that can be fully answered ...   \n",
       "11   Here is a question that can be fully answered ...   \n",
       "12   Based on the given context, here's a question ...   \n",
       "13   Here's a question that can be fully answered b...   \n",
       "14   Here's a rewritten version of the question:\\n\\...   \n",
       "15   What's on the agenda for the Next Gen File For...   \n",
       "16   Here's a rewritten version of the question:\\n\\...   \n",
       "17   Here's a question that can be fully answered b...   \n",
       "18   Here is a question that can be fully answered ...   \n",
       "19   Based on the given context, a question that ca...   \n",
       "20   Here's a question that can be fully answered f...   \n",
       "21   Here's a question that can be fully answered f...   \n",
       "22   Here is a question that can be fully answered ...   \n",
       "23   Here is a question that can be fully answered ...   \n",
       "24   Here is a question that can be fully answered ...   \n",
       "25   Here is a question that can be fully answered ...   \n",
       "26   Here's a question that can be fully answered f...   \n",
       "27   How does integrating package management within...   \n",
       "28   Here's a rewritten version of the question:\\n\\...   \n",
       "29   Here's a question that can be fully answered f...   \n",
       "30   Here's the question that can be fully answered...   \n",
       "31   What are this week's office hour timings, as c...   \n",
       "32   Here's the question:\\n\\n\"What are the proposed...   \n",
       "33   Here's a question that can be fully answered f...   \n",
       "34   Here's a question that can be fully answered f...   \n",
       "35   Here's a question that can be fully answered f...   \n",
       "36   Here is a question that can be fully answered ...   \n",
       "37   What are the main differences between Docker a...   \n",
       "38   Here's the question that can be fully answered...   \n",
       "39   Here's a question that can be fully answered f...   \n",
       "40   Here is a question that can be fully answered ...   \n",
       "41   Here's the question that can be fully answered...   \n",
       "42   Here's a rewritten question that requires mult...   \n",
       "43   Here's a rewritten question that conveys the s...   \n",
       "44   Here's the question that can be fully answered...   \n",
       "45   Here is a question that can be fully answered ...   \n",
       "46   Here's a rewritten version of the question tha...   \n",
       "47   Here is a question that can be fully answered ...   \n",
       "48   Here is a question that can be fully answered ...   \n",
       "49   Here's a question that can be fully answered f...   \n",
       "50   Here is a question that can be fully answered ...   \n",
       "51   What is the main difference between Docker and...   \n",
       "52   Here is a rewritten version of the question:\\n...   \n",
       "53   Here's a question that can be fully answered f...   \n",
       "54   Here's a question that can be fully answered f...   \n",
       "55   Here is a question that can be fully answered ...   \n",
       "56   Here's the question that can be fully answered...   \n",
       "57   Here is a question that can be fully answered ...   \n",
       "58   What is the main difference between Docker and...   \n",
       "59   Here's a question that can be fully answered f...   \n",
       "60   Here's a rewritten version of the question tha...   \n",
       "61   Here's a rewritten version of the question tha...   \n",
       "62   Here's a question that can be fully answered f...   \n",
       "63   Here is the question that can be fully answere...   \n",
       "64   Here's a question that can be fully answered f...   \n",
       "65   Here's a question that can be fully answered f...   \n",
       "66   Here's a rewritten question that meets the rul...   \n",
       "67   Here is a question that can be fully answered ...   \n",
       "68   Here's a question that can be fully answered f...   \n",
       "69   Here's the question that can be fully answered...   \n",
       "70   Here is a question that can be fully answered ...   \n",
       "71   Here is a question that can be fully answered ...   \n",
       "72   Based on the given context, a suitable questio...   \n",
       "73   Here's a question that can be fully answered f...   \n",
       "74   What's Julia's way to identify anonymous varia...   \n",
       "75   Here's a question that can be fully answered f...   \n",
       "76   Here is a question that can be fully answered ...   \n",
       "77   Here is the rewritten question:\\n\\n\"What makes...   \n",
       "78   Here is a question that can be fully answered ...   \n",
       "79   Here's a question that can be fully answered b...   \n",
       "80   Here's a rewritten version of the question tha...   \n",
       "81   Here's a question that can be fully answered f...   \n",
       "82   Here is a question that can be fully answered ...   \n",
       "83   Here's a question that can be fully answered f...   \n",
       "84   What challenges did Hannah face building FicTr...   \n",
       "85   Here's a rewritten question that combines info...   \n",
       "86   What causes SSH connection issues, and how doe...   \n",
       "87   Here is a question that can be fully answered ...   \n",
       "88   Here's a question that can be fully answered f...   \n",
       "89   Here is a question that can be fully answered ...   \n",
       "90   Here's a question that can be fully answered f...   \n",
       "91   Based on the given context, a question that ca...   \n",
       "92   Here is a question that can be fully answered ...   \n",
       "93   Here's a question that can be fully answered f...   \n",
       "94   Here is a question that can be fully answered ...   \n",
       "95   Based on the given context, a suitable questio...   \n",
       "96   Here's a question that can be fully answered f...   \n",
       "97   Here's a question that can be fully answered f...   \n",
       "98   Here's a question that can be fully answered f...   \n",
       "99   Here is a question that can be fully answered ...   \n",
       "100  Here is a question that can be fully answered ...   \n",
       "101  Here's a question that can be fully answered f...   \n",
       "102  Here is a question that can be fully answered ...   \n",
       "103  Here's a question that can be fully answered f...   \n",
       "104  Here's a question that can be fully answered f...   \n",
       "105  Here is a question that can be fully answered ...   \n",
       "106  Here's a question that can be fully answered f...   \n",
       "107  Here's a question that can be fully answered f...   \n",
       "108  Here's a rewritten question that conveys the s...   \n",
       "109  Here's a rewritten version of the question:\\n\\...   \n",
       "110  Here is a rewritten version of the question th...   \n",
       "111  Here's a question that can be fully answered f...   \n",
       "112  Here is a question that can be fully answered ...   \n",
       "113  Here is a question that can be fully answered ...   \n",
       "114  Here is a question that can be fully answered ...   \n",
       "115  Here's a question that can be fully answered f...   \n",
       "116  What's the solution for Philip Hubbard's probl...   \n",
       "117  What's used for exploring matches on the dashb...   \n",
       "118  Here is the question that can be fully answere...   \n",
       "119  Here's the question that can be fully answered...   \n",
       "120  Here's the question that can be fully answered...   \n",
       "121  What percentage of RAM should the `shared_buff...   \n",
       "122  Here's a question that can be fully answered b...   \n",
       "123  Here is a question that can be fully answered ...   \n",
       "124  Based on the given context, a suitable questio...   \n",
       "125  Here's a question that can be fully answered f...   \n",
       "126  What are the conditions that need to be met in...   \n",
       "127  Here is a rewritten question that conveys the ...   \n",
       "128  Here's a rewritten version of the question:\\n\\...   \n",
       "129  How can PostgreSQL performance be optimized fo...   \n",
       "130  Here is the question that can be fully answere...   \n",
       "131  What changes does the Viewer class make to sup...   \n",
       "132  Here's a question that can be fully answered f...   \n",
       "133  Here is a question that can be fully answered ...   \n",
       "134  Here is a question that can be fully answered ...   \n",
       "135  What is the significance of the camera's posit...   \n",
       "136  Here is a question that can be fully answered ...   \n",
       "137  Here is a question that can be fully answered ...   \n",
       "138  Here is a question that can be fully answered ...   \n",
       "139  Here is a question that can be fully answered ...   \n",
       "140  Here's a question that can be fully answered f...   \n",
       "141  Here is a question that can be fully answered ...   \n",
       "142  Here is a question that can be fully answered ...   \n",
       "143  Here's a question that can be fully answered f...   \n",
       "144  Here is a question that can be fully answered ...   \n",
       "145  Here's a question that can be fully answered f...   \n",
       "146  Here is a question that can be fully answered ...   \n",
       "147  Here is a question that can be fully answered ...   \n",
       "148  Here is the question that can be fully answere...   \n",
       "149  Here is a question that can be fully answered ...   \n",
       "150  Here is a question that can be fully answered ...   \n",
       "151  Here is a question that can be fully answered ...   \n",
       "152  Here is a question that can be fully answered ...   \n",
       "153  Here's a question that can be fully answered f...   \n",
       "154  What changes does the Viewer class make to sup...   \n",
       "155  Here's a question that can be fully answered f...   \n",
       "156  Here's a possible rewritten version:\\n\\n\"What ...   \n",
       "157  Here's a rewritten question that meets the rul...   \n",
       "158  Here is a rewritten version of the question th...   \n",
       "159  Here's a rewritten version of the question tha...   \n",
       "160  Here's a rewritten version of the question tha...   \n",
       "161  What drives tile pair generation in the alignm...   \n",
       "162  Here's a rewritten version of the question tha...   \n",
       "163  Here's a possible rewritten version:\\n\\n\"What ...   \n",
       "164  What's the sweet spot between model simplicity...   \n",
       "165  What is the main difference between Docker and...   \n",
       "166  Here's a rewritten version of the question:\\n\\...   \n",
       "167  Here's a question that can be fully answered f...   \n",
       "168  Here's a question that can be fully answered f...   \n",
       "169  Here's the question that can be fully answered...   \n",
       "170  Here is a question that can be fully answered ...   \n",
       "171  What is the main difference between Docker and...   \n",
       "172  Here's a rewritten version of the question tha...   \n",
       "173  Here's a rewritten version of the question tha...   \n",
       "174  Here is a question that can be fully answered ...   \n",
       "175  Here is a question that can be fully answered ...   \n",
       "176  Here is a question that can be fully answered ...   \n",
       "177  Here's a question that can be fully answered f...   \n",
       "178  Here is a question that can be fully answered ...   \n",
       "179  Here's a rewritten version of the question tha...   \n",
       "180  Here's a question that can be fully answered f...   \n",
       "181  Here's a question that can be fully answered f...   \n",
       "182  Here is a question that can be fully answered ...   \n",
       "183  Here is a question that can be fully answered ...   \n",
       "184  Here is a question that can be fully answered ...   \n",
       "185  Here is a question that can be fully answered ...   \n",
       "186  Here's a rewritten question that requires mult...   \n",
       "187  Here's a rewritten version of the question tha...   \n",
       "188  Here's a rewritten question that requires mult...   \n",
       "189  Here's the question that can be fully answered...   \n",
       "190  Here is a question that can be fully answered ...   \n",
       "191  Here is a question that can be fully answered ...   \n",
       "192  Here is a question that can be fully answered ...   \n",
       "193  Here is a question that can be fully answered ...   \n",
       "194  Here is a question that can be fully answered ...   \n",
       "195  Here is a question that can be fully answered ...   \n",
       "196  Here is a question that can be fully answered ...   \n",
       "197  Here is a question that can be fully answered ...   \n",
       "198  What parameters can be used in sage_json.php, ...   \n",
       "199  Here's a rewritten question that requires mult...   \n",
       "200  Here's a rewritten version that requires multi...   \n",
       "\n",
       "                                          ground_truth  \\\n",
       "0    The primary purpose of Akaike information crit...   \n",
       "1    The purpose of the Akaike information criterio...   \n",
       "2    AIC aims to reconcile the trade-off between th...   \n",
       "3    The embedded ChatGPT-like interface has tricks...   \n",
       "4    Sequential storage can have benefits even in h...   \n",
       "5    Sequential storage (i.e., trying to maximize a...   \n",
       "6    The matrix operations performed in this code s...   \n",
       "7    The test is checking the accuracy of the GGESE...   \n",
       "8    The purpose of the QZ decomposition in numeric...   \n",
       "9    The embedded ChatGPT-like interface has featur...   \n",
       "10   The test is checking the accuracy of the GGESE...   \n",
       "11                                       Python 3.10.6   \n",
       "12   The issue causing the kernel crash when using ...   \n",
       "13   During the Next Gen File Formats session at th...   \n",
       "14   The answer to given question is not present in...   \n",
       "15   During the OME conference next week they will ...   \n",
       "16   The answer to given question is not present in...   \n",
       "17   During the 'Next Gen File Formats' session at ...   \n",
       "18   To attach VSCode to a bsub session for remote ...   \n",
       "19   The differences between the arrays 'a', 'b', a...   \n",
       "20   Gert-Jan Both made some changes to the API of ...   \n",
       "21   Running Pkg.update() in a Julia session update...   \n",
       "22   The test is checking if the result of the GGE ...   \n",
       "23   The test is checking if the result of the GGE ...   \n",
       "24   During warping, values for img must be reconst...   \n",
       "25   The expected result of the q @ s @ z.conj().T ...   \n",
       "26   The purpose of the QZ decomposition in linear ...   \n",
       "27   Integrating package management within a progra...   \n",
       "28   You can run a remote VScode session on the sub...   \n",
       "29   Some common topics of humor and criticism abou...   \n",
       "30   Science has developed a *ton* of internal tool...   \n",
       "31   Srini's office hours will begin next week on T...   \n",
       "32   The proposed office hour arrangements are Srin...   \n",
       "33   Davis Bennett suggests that the h5py API shoul...   \n",
       "34   Gert-Jan Both made some changes to the API of ...   \n",
       "35   The purpose of the QZ decomposition in this ma...   \n",
       "36                                  The kernel crashes   \n",
       "37   The main differences between Docker and Singul...   \n",
       "38   The proposed pace of the course is to have a v...   \n",
       "39   To attach VSCode to a bsub session for debuggi...   \n",
       "40                                       Python 3.10.6   \n",
       "41   Davis Bennett's complaint about h5py is that i...   \n",
       "42   Konrad Rokicki's explanation reveals that by d...   \n",
       "43   Robert Lines and Konrad Rokicki balance memory...   \n",
       "44   The autogenerated filenames in the h5py source...   \n",
       "45   The issue with running tasks on workers in a d...   \n",
       "46   h5py doesn't provide a straightforward way to ...   \n",
       "47   The issue of not being able to remove intermed...   \n",
       "48   The issue might be caused by a version mismatc...   \n",
       "49   The limitations of translation and conversion ...   \n",
       "50   To attach VScode to an interactive bsub sessio...   \n",
       "51   The main difference between Docker and Singula...   \n",
       "52   The answer to given question can be inferred f...   \n",
       "53   Nextflow's current approach to memory manageme...   \n",
       "54   The `warp` command in Interpolations.jl produc...   \n",
       "55   The How To interest group meetings will move t...   \n",
       "56   Davis Bennett's complaint is that h5py hangs o...   \n",
       "57   The changes made to the chromatic package rega...   \n",
       "58   The context does not mention Docker or Singula...   \n",
       "59   To address challenges created by heterogeneity...   \n",
       "60   The presenter is Luca Marconato, and the focus...   \n",
       "61   The main differences between the proposed chun...   \n",
       "62   The main differences between the proposed chun...   \n",
       "63   Yann was bored and working as a project manage...   \n",
       "64   Some common topics of humor and criticism rega...   \n",
       "65   The limitations of translation and conversion ...   \n",
       "66   OME-NGFF introduces next-generation file forma...   \n",
       "67   The differences in building FicTrac using diff...   \n",
       "68   Davis Bennett said that the talk about catalog...   \n",
       "69   Lego robotics was introduced as an interesting...   \n",
       "70   Yann was bored and working as a project manage...   \n",
       "71   Yann was bored and working as a project manage...   \n",
       "72   The purpose of the `@multimethod` macro in Jul...   \n",
       "73   The main differences between the proposed chun...   \n",
       "74   The answer is present in context, specifically...   \n",
       "75   Davis Bennett's complaint is that h5py hangs o...   \n",
       "76   Some of the challenges and differences when ru...   \n",
       "77   Juno is suitable for simulating optical system...   \n",
       "78   To attach VSCode to a bsub session for debuggi...   \n",
       "79   The factors that contributed to the spread of ...   \n",
       "80   Gert-Jan Both highlights that using asserts in...   \n",
       "81   Developers face challenges such as a complete ...   \n",
       "82   You should be able to automatically create the...   \n",
       "83   According to Mark Kittisopikul, common feature...   \n",
       "84   Hannah faced challenges with building FicTrac ...   \n",
       "85   Multimethod dispatch in Julia enables multimet...   \n",
       "86   The `login1` ssh host key has changed recently...   \n",
       "87   The issue with running tasks on workers in the...   \n",
       "88   The main differences between the HDF5 fixed ar...   \n",
       "89   The following changes were made to the chromat...   \n",
       "90   Arraylake is a data lake platform for managing...   \n",
       "91   Juno allows users to design and visualise arbi...   \n",
       "92   The reason for sending some features upstream ...   \n",
       "93   Sequential storage (i.e., trying to maximize a...   \n",
       "94   According to Mark Kittisopikul, the reason for...   \n",
       "95                                                 nan   \n",
       "96   The limitations that led K-Optional Software t...   \n",
       "97   According to Robert Lines, the current approac...   \n",
       "98   Discourse is a common hosting solution used by...   \n",
       "99   Some potential challenges or requirements for ...   \n",
       "100  The test is checking the accuracy of the GGESE...   \n",
       "101            The RSA host key for login1 has changed   \n",
       "102  The four main steps involved in aligning overl...   \n",
       "103  Davis Bennett suggests exposing a __exit__() m...   \n",
       "104  The 7000 series train cars used by Mark Kittis...   \n",
       "105  According to Mark Kittisopikul, there are no o...   \n",
       "106  The @multimethod macro is used to define multi...   \n",
       "107  The purpose of hosting a \"virtual\" N5 file via...   \n",
       "108  Developers typically encounter challenges when...   \n",
       "109  The scheduled call time for Mark Kittisopikul'...   \n",
       "110  The retry mechanism in Nextflow prevents jobs ...   \n",
       "111  Nextflow can retry jobs with more memory, as m...   \n",
       "112  The purpose was to introduce and demonstrate t...   \n",
       "113  The primary functions of the SAGE imagery inde...   \n",
       "114  Some potential issues or considerations when u...   \n",
       "115  Mamba ended up taking maybe 2 min. Conda took ...   \n",
       "116  Philip Hubbard's solution for the problem with...   \n",
       "117  To view and navigate tile collections in the R...   \n",
       "118  Go is an open source programming language that...   \n",
       "119  The tentative schedule for the call with HDF G...   \n",
       "120  The purpose of the call is to allow participan...   \n",
       "121                                  1/4 to 1/3 of RAM   \n",
       "122  According to William Katz, the estimated numbe...   \n",
       "123  The SAGE imagery indexer will extract informat...   \n",
       "124  The key differences between the FastAI approac...   \n",
       "125  The limitations that led K-Optional Software t...   \n",
       "126  The conditions that need to be met in order to...   \n",
       "127  Introducing chess by playing with general rule...   \n",
       "128  The answer to given question is present in con...   \n",
       "129  Configuration settings for PostgreSQL performa...   \n",
       "130  The code snippet closes objects. It first call...   \n",
       "131  The Viewer class makes several changes to supp...   \n",
       "132  According to Mark Kittisopikul, common feature...   \n",
       "133  The purpose of setting the `pixelRatio` and `s...   \n",
       "134  The focus of the first Code Review Interest Gr...   \n",
       "135  The camera's position is significant in determ...   \n",
       "136  The purpose of the ray marching iterations is ...   \n",
       "137  The purpose of the change in indexing after ro...   \n",
       "138  React uses an explicit top-down data flow, wit...   \n",
       "139  During warping, values for img must be reconst...   \n",
       "140  The purpose of the 'Introduction to the Wiki' ...   \n",
       "141  The purpose of setting this.clipFillingPlane.v...   \n",
       "142  This command is used to get help and diagnosti...   \n",
       "143                                                nan   \n",
       "144  The purpose of the two Code Review Interest Gr...   \n",
       "145  The UniClust30_database_path provides a refere...   \n",
       "146  According to the context, there are no overnig...   \n",
       "147  The main difference between Akaike Information...   \n",
       "148  The steps involved in generating and aligning ...   \n",
       "149  The key settings used to generate and configur...   \n",
       "150  Some of the challenges when using h5py with di...   \n",
       "151  The limitations of translation and conversion ...   \n",
       "152  The sequence file contains the FASTA paths of ...   \n",
       "153  The issue with Cling's use of LLVM is that it ...   \n",
       "154  The Viewer class supports a camera that has mo...   \n",
       "155  Synology Inc. centralizes data storage and bac...   \n",
       "156  The main differences between the proposed chun...   \n",
       "157  The answer to given question is not present in...   \n",
       "158  To manage share access for SciComp OU groups, ...   \n",
       "159  The key challenge when applying Dask.array.coa...   \n",
       "160  Flipping the depth test when rendering the cli...   \n",
       "161  Tile pair generation in the alignment process ...   \n",
       "162  React's approach to handling mouse events in c...   \n",
       "163  The main app component loads volume data into ...   \n",
       "164  The answer to given question is not present in...   \n",
       "165  Docker containers expect you to enter as root ...   \n",
       "166  The answer to given question is present in con...   \n",
       "167  The recommended approach for storing immutable...   \n",
       "168  The `warp` command in Julia produces an output...   \n",
       "169  The agenda has not been set, but it's more abo...   \n",
       "170  The code snippet generates a test texture for ...   \n",
       "171  The main difference between Docker and Singula...   \n",
       "172  When test data kicks in, there is an initial r...   \n",
       "173  The answer to given question is not present in...   \n",
       "174  The purpose of adding items to the 'Need Post ...   \n",
       "175  NEW_WEBSITE_NAME, dbi, DBI_STRING, username, U...   \n",
       "176  The file permission issue might have been caus...   \n",
       "177  To create a mini-stack using the spark process...   \n",
       "178  The system will extract information from the i...   \n",
       "179  When you enable test data, it triggers an extr...   \n",
       "180  It is not currently possible to create a Gauss...   \n",
       "181  The answer to given question is not present in...   \n",
       "182  Some examples of how to perform diagnostics on...   \n",
       "183  Juno is a Python-based graphical package for o...   \n",
       "184  The two image alignment pipelines discussed in...   \n",
       "185  The steps involved in uploading imagery for Ne...   \n",
       "186  To synchronize publication decisions with SAGE...   \n",
       "187  To balance performance for heavy write scenari...   \n",
       "188  The main differences between ZEP2 chunk index ...   \n",
       "189  Rust isn't the best choice if your app needs a...   \n",
       "190  Science team leads are invited to discuss thei...   \n",
       "191  Science team leads are invited to discuss thei...   \n",
       "192  When troubleshooting issues with accessing sha...   \n",
       "193  The recommended way to close open objects rela...   \n",
       "194  The different options available to run the Sag...   \n",
       "195  The necessary environment variables and JWT to...   \n",
       "196  The challenges and limitations associated with...   \n",
       "197  The test is checking if the result of the GGE ...   \n",
       "198  The parameters that can be used in sage_json.p...   \n",
       "199  The typical workflow for uploading searchable ...   \n",
       "200  The proposed fix for file format heterogeneity...   \n",
       "\n",
       "                                              contexts  \\\n",
       "0    [Mark Kittisopikul said: Greg Fleishman, I was...   \n",
       "1    [Mark Kittisopikul said: Greg Fleishman, I was...   \n",
       "2    [Mark Kittisopikul said: Greg Fleishman, I was...   \n",
       "3    [William Katz said: https://twitter.com/maxhod...   \n",
       "4    [William Katz said: Some links from my second ...   \n",
       "5    [William Katz said: Some links from my second ...   \n",
       "6    [.10534273, -0.5556871 ,\\n         0.8352932 ,...   \n",
       "7    [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "8    [.10534273, -0.5556871 ,\\n         0.8352932 ,...   \n",
       "9    [William Katz said: https://twitter.com/maxhod...   \n",
       "10   [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "11   [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "12   [.        ,  0.        ,  0.        ,  0.     ...   \n",
       "13   [Ulrike Boehm said: For those of you intereste...   \n",
       "14   [.10534273, -0.5556871 ,\\n         0.8352932 ,...   \n",
       "15   [Ulrike Boehm said: For those of you intereste...   \n",
       "16   [.        ,  0.        ,  0.        ,  0.     ...   \n",
       "17   [Ulrike Boehm said: For those of you intereste...   \n",
       "18   [Eric Wait said: Has anyone attached VScode to...   \n",
       "19   [ol=1.19209e-05\\nE   \\nE   Mismatched elements...   \n",
       "20   [Gert-Jan Both said: Welcome everyone! As you ...   \n",
       "21   [Mark Kittisopikul said: Something like the en...   \n",
       "22   [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "23   [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "24   [Davis Bennett said: after rotation of the `[1...   \n",
       "25   [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "26   [.10534273, -0.5556871 ,\\n         0.8352932 ,...   \n",
       "27   [Mark Kittisopikul said: Something like the en...   \n",
       "28   [Eric Wait said: Has anyone attached VScode to...   \n",
       "29   [Mark Kittisopikul said: I will await your upd...   \n",
       "30   [William Katz said: https://twitter.com/maxhod...   \n",
       "31   [William Katz said:  I propose we start this w...   \n",
       "32   [William Katz said:  I propose we start this w...   \n",
       "33   [Davis Bennett said: loving these filenames in...   \n",
       "34   [Gert-Jan Both said: Welcome everyone! As you ...   \n",
       "35   [.10534273, -0.5556871 ,\\n         0.8352932 ,...   \n",
       "36   [.        ,  0.        ,  0.        ,  0.     ...   \n",
       "37   [Robert Lines said: The biggest gotcha we have...   \n",
       "38   [William Katz said:  I propose we start this w...   \n",
       "39   [Eric Wait said: Has anyone attached VScode to...   \n",
       "40   [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "41   [Davis Bennett said: loving these filenames in...   \n",
       "42   [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "43   [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "44   [Davis Bennett said: loving these filenames in...   \n",
       "45   [ in get\\n      results = self.gather(packed, ...   \n",
       "46   [ the big headaches when trying to use h5py wi...   \n",
       "47   [Greg Fleishman said: Is anyone aware of any c...   \n",
       "48   [ in get\\n      results = self.gather(packed, ...   \n",
       "49   [William Katz said: https://www.biorxiv.org/co...   \n",
       "50   [Eric Wait said: Has anyone attached VScode to...   \n",
       "51   [Robert Lines said: The biggest gotcha we have...   \n",
       "52   [Mary Lay said: Best way to set up mamba when ...   \n",
       "53   [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "54   [ points are handled - pass img as an\\n  Abst...   \n",
       "55   [Mark Kittisopikul said: We are moving How To ...   \n",
       "56   [Davis Bennett said: loving these filenames in...   \n",
       "57   [_ramps`) now return phase directly as `ndarra...   \n",
       "58   [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "59   [Mark Kittisopikul said: \\nHello *<!channel>*,...   \n",
       "60   [Mark Kittisopikul said: \\nHello *<!channel>*,...   \n",
       "61   [Mark Kittisopikul said: I posted a comparison...   \n",
       "62   [Mark Kittisopikul said: I posted a comparison...   \n",
       "63   [William Katz said: https://corecursive.com/da...   \n",
       "64   [Mark Kittisopikul said: I will await your upd...   \n",
       "65   [William Katz said: https://www.biorxiv.org/co...   \n",
       "66   [William Katz said: https://www.biorxiv.org/co...   \n",
       "67   [Davis Bennett said: Eric Wait you were recomm...   \n",
       "68   [Davis Bennett said: reminder:  today at 2:45 ...   \n",
       "69   [Philip Hubbard said: My twins are in kinderga...   \n",
       "70   [William Katz said: https://corecursive.com/da...   \n",
       "71   [William Katz said: https://corecursive.com/da...   \n",
       "72   [               \"argument must be a block\")\\n ...   \n",
       "73   [Mark Kittisopikul said: I posted a comparison...   \n",
       "74   [               \"argument must be a block\")\\n ...   \n",
       "75   [Davis Bennett said: loving these filenames in...   \n",
       "76   [Robert Lines said: The biggest gotcha we have...   \n",
       "77   [Srini said: https://twitter.com/mariescopy/st...   \n",
       "78   [Eric Wait said: Has anyone attached VScode to...   \n",
       "79   [William Katz said: Some interesting data from...   \n",
       "80   [\\n Examples and tests still need to be updat...   \n",
       "81   [Davis Bennett said: can anyone make sense of ...   \n",
       "82   [David Ackerman said: I can now run a sample d...   \n",
       "83   [Mark Kittisopikul said: I've seen Synology us...   \n",
       "84   [Davis Bennett said: Eric Wait you were recomm...   \n",
       "85   [               \"argument must be a block\")\\n ...   \n",
       "86   [Stuart Berg said: Robert Lines Ken Carlile Ha...   \n",
       "87   [ in get\\n      results = self.gather(packed, ...   \n",
       "88   [Mark Kittisopikul said: Numcodecs is in urgen...   \n",
       "89   [_ramps`) now return phase directly as `ndarra...   \n",
       "90   [Davis Bennett said: reminder:  today at 2:45 ...   \n",
       "91   [Srini said: https://twitter.com/mariescopy/st...   \n",
       "92   [Mark Kittisopikul said: https://root.cern/blo...   \n",
       "93   [William Katz said: Some links from my second ...   \n",
       "94   [Mark Kittisopikul said: Numcodecs is in urgen...   \n",
       "95   [Philip Hubbard said: FastAI supports \"augment...   \n",
       "96   [William Katz said: Recent blog post on why a ...   \n",
       "97   [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "98   [Habib Bukhari said: Or just use our own host....   \n",
       "99   [Habib Bukhari said: Or just use our own host....   \n",
       "100  [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "101  [Stuart Berg said: Robert Lines Ken Carlile Ha...   \n",
       "102  [Alignment Guide\\nTitle: Alignment Guide\\nAuth...   \n",
       "103  [Davis Bennett said: loving these filenames in...   \n",
       "104  [-get-more-frequent-rail-service.cfm\\nMark Kit...   \n",
       "105  [Mark Kittisopikul said: Grabbed some photos o...   \n",
       "106  [               \"argument must be a block\")\\n ...   \n",
       "107  [Stuart Berg said: Marwan Zouinkhi In the thre...   \n",
       "108  [Davis Bennett said: can anyone make sense of ...   \n",
       "109  [Mark Kittisopikul said: Is there anyone else ...   \n",
       "110  [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "111  [Konrad Rokicki said: Robert Lines I was wrong...   \n",
       "112  [WikiTalkSept2006\\nTitle: WikiTalkSept2006\\nAu...   \n",
       "113  [SAGE imagery indexer\\nTitle: SAGE imagery ind...   \n",
       "114  [\\n Examples and tests still need to be updat...   \n",
       "115  [Mary Lay said: Best way to set up mamba when ...   \n",
       "116  [Philip Hubbard said: Does anyone else have tr...   \n",
       "117  [\\napproximation as a rough alignment. The rig...   \n",
       "118  [Mark Kittisopikul said: Go 1.18 gets generics...   \n",
       "119  [Mark Kittisopikul said: Is there anyone else ...   \n",
       "120  [Mark Kittisopikul said: Is there anyone else ...   \n",
       "121  [PostgreSQL Performance Tuning\\nTitle: Postgre...   \n",
       "122  [William Katz said: Some interesting data from...   \n",
       "123  [SAGE imagery indexer\\nTitle: SAGE imagery ind...   \n",
       "124  [Philip Hubbard said: FastAI supports \"augment...   \n",
       "125  [William Katz said: Recent blog post on why a ...   \n",
       "126  [Habib Bukhari said: Or just use our own host....   \n",
       "127  [Philip Hubbard said: My twins are in kinderga...   \n",
       "128  [Philip Hubbard said: FastAI supports \"augment...   \n",
       "129  [PostgreSQL Performance Tuning\\nTitle: Postgre...   \n",
       "130  [            self.id._close_open_objects(h5f.O...   \n",
       "131  [ // \"RedFormat\" is not documented, but used h...   \n",
       "132  [Mark Kittisopikul said: I've seen Synology us...   \n",
       "133  [     this.renderer.setClearColor(\"#000000\")\\n...   \n",
       "134  [William Katz said: The next two Code Review I...   \n",
       "135  [, this.camera)\\n        // Updated, for camer...   \n",
       "136  [ length is just delta.\\n      float deltaDire...   \n",
       "137  [Davis Bennett said: after rotation of the `[1...   \n",
       "138  [, this.camera)\\n        // Updated, for camer...   \n",
       "139  [Davis Bennett said: after rotation of the `[1...   \n",
       "140  [WikiTalkSept2006\\nTitle: WikiTalkSept2006\\nAu...   \n",
       "141  [.src = canvas.toDataURL()\\n        img.style....   \n",
       "142  [Alphafold\\nTitle: Alphafold\\nAuthors: Goran C...   \n",
       "143  [ mount the storage\\n\\n  * Is the computer is ...   \n",
       "144  [William Katz said: The next two Code Review I...   \n",
       "145  [uniref90/uniref90.fasta \\\\n    --mgnify_datab...   \n",
       "146  [Mark Kittisopikul said: Grabbed some photos o...   \n",
       "147  [Mark Kittisopikul said: Greg Fleishman, I was...   \n",
       "148  [ process.  \\n  \\n\\n    2. Create a render sta...   \n",
       "149  [    }\\n      componentWillUnmount() {\\n      ...   \n",
       "150  [ the big headaches when trying to use h5py wi...   \n",
       "151  [William Katz said: https://www.biorxiv.org/co...   \n",
       "152  [Alphafold\\nTitle: Alphafold\\nAuthors: Goran C...   \n",
       "153  [Mark Kittisopikul said: https://root.cern/blo...   \n",
       "154  [ // \"RedFormat\" is not documented, but used h...   \n",
       "155  [Mark Kittisopikul said: I've seen Synology us...   \n",
       "156  [Mark Kittisopikul said: I posted a comparison...   \n",
       "157  [rootDirectory /nrs/flyem/render/scapes/khairy...   \n",
       "158  [Troubleshooting common Janelia Shared Storage...   \n",
       "159  [Davis Bennett said: if anyone needs to make n...   \n",
       "160  [.src = canvas.toDataURL()\\n        img.style....   \n",
       "161  [ are intensity based (due to the lower\\nresol...   \n",
       "162  [, this.camera)\\n        // Updated, for camer...   \n",
       "163  [SCA 3D Graphics Solution: Direct Volume Rende...   \n",
       "164  [Mark Kittisopikul said: Sometimes the simplic...   \n",
       "165  [Robert Lines said: The biggest gotcha we have...   \n",
       "166  [Mark Kittisopikul said: We are moving How To ...   \n",
       "167  [William Katz said: Konrad Rokicki Davis Benne...   \n",
       "168  [ points are handled - pass img as an\\n  Abst...   \n",
       "169  [Mark Kittisopikul said: Is there anyone else ...   \n",
       "170  [ data.byteLength + \" bytes, converted \" + dat...   \n",
       "171  [Robert Lines said: The biggest gotcha we have...   \n",
       "172  [ data.byteLength + \" bytes, converted \" + dat...   \n",
       "173  [Philip Hubbard said: FastAI supports \"augment...   \n",
       "174  [63x-left_dorsal. Adding to folder Need Post P...   \n",
       "175  [ the lines have been loaded previously\\n\\n###...   \n",
       "176  [Greg Fleishman said: Is anyone aware of any c...   \n",
       "177  [rootDirectory /nrs/flyem/render/scapes/khairy...   \n",
       "178  [SAGE imagery indexer\\nTitle: SAGE imagery ind...   \n",
       "179  [ data.byteLength + \" bytes, converted \" + dat...   \n",
       "180  [Davis Bennett said: if anyone needs to make n...   \n",
       "181  [Mark Kittisopikul said: I will await your upd...   \n",
       "182  [ full alignment solve. The following are some...   \n",
       "183  [Srini said: https://twitter.com/mariescopy/st...   \n",
       "184  [\\napproximation as a rough alignment. The rig...   \n",
       "185  [Uploading imagery for NeuronBridge\\nTitle: Up...   \n",
       "186  [How to Synchronize Publication Decisions to S...   \n",
       "187  [PostgreSQL Performance Tuning\\nTitle: Postgre...   \n",
       "188  [Mark Kittisopikul said: I posted a comparison...   \n",
       "189  [William Katz said: tl;dr: Rust is good at som...   \n",
       "190  [Talk Science with SciComp Software\\nTitle: Ta...   \n",
       "191  [Talk Science with SciComp Software\\nTitle: Ta...   \n",
       "192  [ (devfs, local, nobrowse)\\n        /dev/disk3...   \n",
       "193  [ the big headaches when trying to use h5py wi...   \n",
       "194  [Sage-based External Website Cross-loader\\nTit...   \n",
       "195  [Uploading imagery for NeuronBridge\\nTitle: Up...   \n",
       "196  [Flattening\\nTitle: Flattening\\nAuthors: Unkno...   \n",
       "197  [e-01,... 0.36549678, 0.9152956 ,\\n       1.01...   \n",
       "198  [SAGE Ajax\\nTitle: SAGE Ajax\\nAuthors: Rob Svi...   \n",
       "199  [-flylight-color-depth\\n\\nThe code you'll need...   \n",
       "200  [Mark Kittisopikul said: \\nHello *<!channel>*,...   \n",
       "\n",
       "                                                answer  __index_level_0__  \\\n",
       "0    AIC estimates the relative quality of each mod...                  0   \n",
       "1    AIC estimates the relative quality of statisti...                  1   \n",
       "2    AIC aims to balance the trade-off between over...                  2   \n",
       "3    The embedded ChatGPT-like interface allows use...                  3   \n",
       "4    Sequential storage has benefits in highly para...                  4   \n",
       "5    Sequential storage offers benefits for high-th...                  5   \n",
       "6    Matrix multiplication and decomposition operat...                  6   \n",
       "7    The test is checking the accuracy of the GGESE...                  7   \n",
       "8    The QZ decomposition in numerical computation ...                  8   \n",
       "9    The embedded ChatGPT-like interface allows for...                  9   \n",
       "10                                            Python 3                 10   \n",
       "11   The kernel crash when using data augmentation ...                 11   \n",
       "12   The Next Gen File Formats session at the OME c...                 12   \n",
       "13   Yes, a matrix can be decomposed into its ortho...                 13   \n",
       "14   What is the topic of discussion at the OME ses...                 14   \n",
       "15   Cristian Goina's code may behave differently w...                 15   \n",
       "16   The 'Next Gen File Formats' session at the OME...                 16   \n",
       "17   To attach VSCode to a bsub session for remote ...                 17   \n",
       "18   The array 'a' contains integer values, the arr...                 18   \n",
       "19   Gert-Jan Both made changes to the API of xray ...                 19   \n",
       "20   Running `Pkg.update()` in a Julia session upda...                 20   \n",
       "21   The test is checking if the result of the GGE ...                 21   \n",
       "22   The test is checking if the result of the GGE ...                 22   \n",
       "23   The values are reconstructed at arbitrary loca...                 23   \n",
       "24   The expected result of the `q @ s @ z.conj().T...                 24   \n",
       "25   The QZ decomposition in linear algebra is util...                 25   \n",
       "26   Integrating package management within a progra...                 26   \n",
       "27   To establish a remote VScode dev env for bsub ...                 27   \n",
       "28   Repeat: Davis Bennett discussed the importance...                 28   \n",
       "29   Science has developed internal tools such as m...                 29   \n",
       "30   The office hours for this week are scheduled f...                 30   \n",
       "31   The office hours with Srini Turaga are schedul...                 31   \n",
       "32   Davis Bennett suggests improving the h5py API ...                 32   \n",
       "33   Gert-Jan Both made changes to the API of xray ...                 33   \n",
       "34   The purpose of the QZ decomposition in this ma...                 34   \n",
       "35   Cristian Goina does not run his code with the ...                 35   \n",
       "36   Docker containers require sudo privileges to b...                 36   \n",
       "37   The course pace involves meetings every other ...                 37   \n",
       "38   To attach VSCode to a bsub session for debuggi...                 38   \n",
       "39   Davis Bennett's concern with h5py is its tende...                 39   \n",
       "40   Konrad Rokicki's explanation and Robert Lines'...                 40   \n",
       "41   Robert Lines and Konrad Rokicki balance memory...                 41   \n",
       "42   The autogenerated filenames in the h5py source...                 42   \n",
       "43   Potential causes for issues with running tasks...                 43   \n",
       "44   The absence of a direct method to close datase...                 44   \n",
       "45   The issue of not being able to remove intermed...                 45   \n",
       "46   The issue with running tasks in the distribute...                 46   \n",
       "47   Translation and conversion approaches face lim...                 47   \n",
       "48   To attach VScode to an interactive bsub sessio...                 48   \n",
       "49   Docker containers typically require sudo privi...                 49   \n",
       "50                         Mamba is faster than Conda.                 50   \n",
       "51   Nextflow's current approach to memory manageme...                 51   \n",
       "52   The `warp` command in Interpolations.jl produc...                 52   \n",
       "53   The schedule of the How To interest group meet...                 53   \n",
       "54   Davis Bennett's complaint about h5py is relate...                 54   \n",
       "55   The `chromatix` package was updated to include...                 55   \n",
       "56   The purpose of extending the OME-NGFF open for...                 56   \n",
       "57   Luca Marconato is presenting at tomorrow's sem...                 57   \n",
       "58   The proposed chunk index includes an additiona...                 58   \n",
       "59   The proposed chunk index in the ZEP2 spec diff...                 59   \n",
       "60   Yann Collet's hobby of creating a game for his...                 60   \n",
       "61   Davis Bennett discussed the importance of vect...                 61   \n",
       "62   Translation and conversion approaches face lim...                 62   \n",
       "63   NGFF addresses limitations in accessing bioima...                 63   \n",
       "64   Eric Wait's experience with building FicTrac f...                 64   \n",
       "65   The purpose of the talk about cataloging versi...                 65   \n",
       "66   Introducing a child to Lego robotics at the ag...                 66   \n",
       "67   Yann Collet's interest in data compression was...                 67   \n",
       "68   Yann Collet, a former project manager, transit...                 68   \n",
       "69   The purpose of the `@multimethod` macro in Jul...                 69   \n",
       "70   The proposed chunk index involves an extra 4-b...                 70   \n",
       "71   Julia's method for identifying anonymous varia...                 71   \n",
       "72   Davis Bennett's concern is related to how h5py...                 72   \n",
       "73   Running daemon services inside Singularity con...                 73   \n",
       "74   Juno's suitability for simulating optical syst...                 74   \n",
       "75   To attach VSCode to a bsub session for debuggi...                 75   \n",
       "76   The spread of COVID-19 among attendees at SIGG...                 76   \n",
       "77   Gert-Jan Both points out the potential issue o...                 77   \n",
       "78   There is no mention of Davis Bennett or any di...                 78   \n",
       "79   To expand the current single-user setup to sup...                 79   \n",
       "80   Mark Kittisopikul's information does not menti...                 80   \n",
       "81   Hannah encountered syntax challenges with CMak...                 81   \n",
       "82   The Julia construct that enables multimethod d...                 82   \n",
       "83   SSH connection issues can arise due to various...                 83   \n",
       "84   Cristian Goina's suspicion that a version mism...                 84   \n",
       "85   The HDF5 fixed array data block and the propos...                 85   \n",
       "86   The changes made to the chromatix elements and...                 86   \n",
       "87   Davis Bennett mentions Arraylake in the contex...                 87   \n",
       "88   Juno, a Python-based graphical package for opt...                 88   \n",
       "89   To reduce maintenance efforts, some features a...                 89   \n",
       "90   Sequential storage in highly parallel data ser...                 90   \n",
       "91   Mark Kittisopikul mentioned that the reason fo...                 91   \n",
       "92   The key differences between the FastAI approac...                 92   \n",
       "93   The limitations that led K-Optional Software t...                 93   \n",
       "94   The current approach to setting memory limits ...                 94   \n",
       "95   The common hosting solution used by many libra...                 95   \n",
       "96   Some potential challenges or requirements for ...                 96   \n",
       "97   The RSA host key for the `login1` SSH host has...                 97   \n",
       "98   The four main steps are Data Ingestion, Point-...                 98   \n",
       "99   Davis Bennett suggests exposing a __exit__() m...                 99   \n",
       "100  The 7000 series train cars used by Mark Kittis...                100   \n",
       "101  You will be given parking instructions at the ...                101   \n",
       "102  The `@multimethod` macro in Julia programming ...                102   \n",
       "103  The purpose of hosting a virtual N5 file via a...                103   \n",
       "104  Developers often encounter difficulties when u...                104   \n",
       "105  Mark Kittisopikul's meeting with HDF Group is ...                105   \n",
       "106  Nextflow jobs are not terminated by the OOM ki...                106   \n",
       "107  Nextflow has the capability to retry jobs with...                107   \n",
       "108  The purpose of Don Olbris' introduction-demons...                108   \n",
       "109  The primary functions of the SAGE imagery inde...                109   \n",
       "110  Gert-Jan Both highlights potential issues or c...                110   \n",
       "111  The solving environment time when creating con...                111   \n",
       "112  Disconnecting from the VPN resolves Philip Hub...                112   \n",
       "113  The tool used for exploring matches on the das...                113   \n",
       "114         Go is an open source programming language.                114   \n",
       "115  The tentative schedule for the call with HDF G...                115   \n",
       "116  The purpose of the call arranged by HDF Group ...                116   \n",
       "117  The `shared_buffers` setting in PostgreSQL sho...                117   \n",
       "118  Extrapolating on polling, they estimate 2000 o...                118   \n",
       "119  The SAGE imagery indexer will extract the foll...                119   \n",
       "120  Philip Hubbard discusses the key differences b...                120   \n",
       "121  K-Optional Software decided to move away from ...                121   \n",
       "122  To qualify for free forum hosting from Discour...                122   \n",
       "123  How can you engage a young child in a strategi...                123   \n",
       "124  Using 'perturbations' in FastAI's `DataBlock` ...                124   \n",
       "125  Optimize PostgreSQL performance for database o...                125   \n",
       "126  The code snippet, when closing objects, ensure...                126   \n",
       "127  The Viewer class adjusts the camera position b...                127   \n",
       "128  Setting the `pixelRatio` and `setSize` methods...                128   \n",
       "129  The focus of the first Code Review Interest Gr...                129   \n",
       "130  The camera's position plays a vital role in de...                130   \n",
       "131  The purpose of the ray marching iterations in ...                131   \n",
       "132  The purpose of the change in indexing after ro...                132   \n",
       "133  React uses an explicit top-down data flow appr...                133   \n",
       "134  The purpose of the 'Introduction to the Wiki' ...                134   \n",
       "135  The purpose of setting `this.clipFillingPlane....                135   \n",
       "136  The `singularity run` command in AlphaFold is ...                136   \n",
       "137  Common issues with network file system permiss...                137   \n",
       "138  The purpose of the two Code Review Interest Gr...                138   \n",
       "139  The purpose of the UniClust30_database_path in...                139   \n",
       "140  You will be given parking instructions at the ...                140   \n",
       "141  The main difference between Akaike Information...                141   \n",
       "142  The steps to generate and align image metadata...                142   \n",
       "143  The key settings used to generate and configur...                143   \n",
       "144  Transferring data between the CPU and the GPU ...                144   \n",
       "145  Translation and conversion approaches face lim...                145   \n",
       "146  The sequence file contains the FASTA paths of ...                146   \n",
       "147  Cling's use of LLVM 5 is considered an issue a...                147   \n",
       "148  Synology NAS devices offer features such as ce...                148   \n",
       "149  The proposed chunk index and HDF5 fixed array ...                149   \n",
       "150  To set up and run a spark process using `rende...                150   \n",
       "151  To manage share access for SciComp OU groups, ...                151   \n",
       "152  The potential challenge in applying `Dask.arra...                152   \n",
       "153  Flipping the depth test when rendering the cli...                153   \n",
       "154  The tile pair generation in the alignment proc...                154   \n",
       "155  React's typical approach involves using event ...                155   \n",
       "156  The main app component of the SCA 3D Graphics ...                156   \n",
       "157  The sweet spot between model simplicity and fi...                157   \n",
       "158  Docker containers require sudo privileges to b...                158   \n",
       "159  To balance conflicting events with our regular...                159   \n",
       "160  Store immutable images like registered graysca...                160   \n",
       "161  The `warp` command in Julia transforms an inpu...                161   \n",
       "162  The agenda for the meeting scheduled by HDF Gr...                162   \n",
       "163  The code snippet in its `createTestTexture` fu...                163   \n",
       "164  Docker containers require sudo privileges to b...                164   \n",
       "165  When test data is activated, the workaround fo...                165   \n",
       "166  Diffrax updates could potentially influence th...                166   \n",
       "167  The purpose of adding items to the Need Post P...                167   \n",
       "168  To configure a new website for the database in...                168   \n",
       "169  The file permission issue when trying to remov...                169   \n",
       "170  Clone the simple Java Spark project, ensure Ma...                170   \n",
       "171  The SAGE imagery indexer will extract the foll...                171   \n",
       "172  Enabling test data replaces medical or neuron ...                172   \n",
       "173  It is not currently possible to create a Gauss...                173   \n",
       "174  For performing diagnostics on image stacks usi...                174   \n",
       "175  Juno is a complete library with a graphical us...                175   \n",
       "176  The two image alignment pipelines discussed in...                176   \n",
       "177  The steps involved in uploading imagery for Ne...                177   \n",
       "178  To synchronize publication decisions with SAGE...                178   \n",
       "179  Adjust the `checkpoint_segments` parameter to ...                179   \n",
       "180  The key differences between ZEP2 chunk index a...                180   \n",
       "181  When deciding whether to use Rust at a startup...                181   \n",
       "182  The purpose of the Talk Science with SciComp S...                182   \n",
       "183  The purpose of the Talk Science with SciComp S...                183   \n",
       "184  When troubleshooting issues with accessing sha...                184   \n",
       "185  The recommended way to close open objects rela...                185   \n",
       "186  The different options available to run the Sag...                186   \n",
       "187  An environment variable named \"CONFIG_SERVER_U...                187   \n",
       "188  Some challenges and limitations associated wit...                188   \n",
       "189  The test is checking if the result of the GGE ...                189   \n",
       "190  The parameters that can be used in sage_json.p...                190   \n",
       "191  The typical workflow for uploading searchable ...                191   \n",
       "192  The proposed solution for addressing file form...                192   \n",
       "193  Factors to consider when evaluating the comple...                193   \n",
       "194  The `MAX_STEPS` variable in ray marching deter...                194   \n",
       "195  The challenges and difficulties encountered wh...                195   \n",
       "196  Synology is not mentioned in the provided cont...                196   \n",
       "197  The key evaluation criteria for choosing a bac...                197   \n",
       "198  What key considerations should you prioritize ...                198   \n",
       "199  To restart an NX NoMachine session on a Login ...                199   \n",
       "200  Data access approaches directly impact analysi...                200   \n",
       "\n",
       "     context_precision  faithfulness  answer_relevancy  context_recall  \n",
       "0                  1.0      1.000000          0.611382        1.000000  \n",
       "1                  1.0      1.000000          0.609881        1.000000  \n",
       "2                  1.0      1.000000          0.713180        1.000000  \n",
       "3                  1.0      0.000000          0.681673        1.000000  \n",
       "4                  1.0      0.833333          0.668477        1.000000  \n",
       "5                  1.0      1.000000          0.565915        1.000000  \n",
       "6                  0.0      1.000000          0.606350        1.000000  \n",
       "7                  0.0      0.000000          0.519669        1.000000  \n",
       "8                  1.0      1.000000          0.644522        1.000000  \n",
       "9                  1.0      1.000000          0.715057        1.000000  \n",
       "10                 0.0      1.000000          0.561170        1.000000  \n",
       "11                 1.0      0.000000          0.670002        1.000000  \n",
       "12                 1.0      0.000000          0.729890        0.000000  \n",
       "13                 1.0      0.500000          0.512027        1.000000  \n",
       "14                 0.0      0.250000          0.372495        0.000000  \n",
       "15                 1.0      0.000000          0.000000        1.000000  \n",
       "16                 0.0           NaN          0.672138             NaN  \n",
       "17                 1.0           NaN          0.443889        1.000000  \n",
       "18                 1.0      0.500000          0.540272        1.000000  \n",
       "19                 0.0      0.000000          0.477950             NaN  \n",
       "20                 1.0      0.000000          0.568042        1.000000  \n",
       "21                 1.0      0.000000          0.577780        0.000000  \n",
       "22                 1.0      1.000000          0.000000        1.000000  \n",
       "23                 0.0      0.000000          0.394914        1.000000  \n",
       "24                 1.0      0.500000          0.625442             NaN  \n",
       "25                 0.0      1.000000          0.680793        0.000000  \n",
       "26                 0.0      0.000000          0.566521        1.000000  \n",
       "27                 1.0      0.250000          0.490028        0.600000  \n",
       "28                 1.0      0.000000          0.474953        1.000000  \n",
       "29                 1.0      0.333333          0.341040        1.000000  \n",
       "30                 1.0      1.000000          0.313135        1.000000  \n",
       "31                 1.0      0.250000          0.761365        1.000000  \n",
       "32                 1.0      0.000000          0.569172        1.000000  \n",
       "33                 1.0      0.166667          0.581201             NaN  \n",
       "34                 1.0      0.500000          0.566109        1.000000  \n",
       "35                 0.0      0.000000          0.000000        1.000000  \n",
       "36                 1.0      0.000000          0.641116        1.000000  \n",
       "37                 1.0      0.000000          0.793306        0.500000  \n",
       "38                 1.0      0.000000          0.408650        1.000000  \n",
       "39                 1.0      0.000000          0.519172        1.000000  \n",
       "40                 1.0      0.000000          0.585413        1.000000  \n",
       "41                 1.0      0.400000          0.504285             NaN  \n",
       "42                 1.0      1.000000          0.480277        1.000000  \n",
       "43                 1.0      0.000000          0.484702        1.000000  \n",
       "44                 0.0      0.750000          0.617290             NaN  \n",
       "45                 1.0      0.400000          0.596358        1.000000  \n",
       "46                 1.0      0.000000          0.457028             NaN  \n",
       "47                 1.0      0.125000          0.539139        1.000000  \n",
       "48                 1.0      0.000000          0.576444        1.000000  \n",
       "49                 1.0      0.000000          0.480726        1.000000  \n",
       "50                 1.0      1.000000          0.567529        1.000000  \n",
       "51                 1.0      0.000000          0.606333        0.750000  \n",
       "52                 1.0      0.000000          0.541326        1.000000  \n",
       "53                 1.0      0.000000          0.580011        1.000000  \n",
       "54                 1.0      0.250000          0.510864             NaN  \n",
       "55                 1.0           NaN          0.548583             NaN  \n",
       "56                 NaN      1.000000          0.528109             NaN  \n",
       "57                 1.0      0.000000          0.627679        0.916667  \n",
       "58                 0.0      0.000000          0.611832        0.000000  \n",
       "59                 1.0      0.250000          0.557922        1.000000  \n",
       "60                 1.0      0.000000          0.510281        1.000000  \n",
       "61                 1.0      0.000000          0.465607        1.000000  \n",
       "62                 1.0      0.000000          0.508818        1.000000  \n",
       "63                 1.0      0.000000          0.823630        1.000000  \n",
       "64                 1.0      0.000000          0.557039        1.000000  \n",
       "65                 1.0      0.333333          0.532606        1.000000  \n",
       "66                 1.0      0.000000          0.551096        1.000000  \n",
       "67                 1.0      0.000000          0.492466        0.500000  \n",
       "68                 1.0      0.000000          0.506962        1.000000  \n",
       "69                 1.0      0.000000          0.501368        1.000000  \n",
       "70                 1.0      1.000000          0.509726        1.000000  \n",
       "71                 1.0      1.000000          0.593124        1.000000  \n",
       "72                 1.0      0.000000          0.454208        0.500000  \n",
       "73                 1.0      0.166667          0.534322        1.000000  \n",
       "74                 1.0      0.000000          0.466227        1.000000  \n",
       "75                 1.0      0.400000          0.493490             NaN  \n",
       "76                 1.0      0.000000          0.460099        0.800000  \n",
       "77                 1.0      0.000000          0.571014        1.000000  \n",
       "78                 1.0      0.500000          0.540843        1.000000  \n",
       "79                 1.0           NaN          0.527815        1.000000  \n",
       "80                 1.0      1.000000          0.000000        1.000000  \n",
       "81                 1.0      0.000000          0.661283        1.000000  \n",
       "82                 1.0      0.000000          0.692545        0.750000  \n",
       "83                 1.0      0.000000          0.527518        1.000000  \n",
       "84                 1.0      0.000000          0.561333        1.000000  \n",
       "85                 1.0      0.250000          0.487407        1.000000  \n",
       "86                 1.0      0.000000          0.570087        1.000000  \n",
       "87                 1.0      0.000000          0.551397             NaN  \n",
       "88                 0.5      0.000000          0.482381        1.000000  \n",
       "89                 1.0      0.500000          0.684598        1.000000  \n",
       "90                 1.0      0.500000          0.547317        1.000000  \n",
       "91                 1.0      0.000000          0.509434        1.000000  \n",
       "92                 1.0           NaN          0.541482        1.000000  \n",
       "93                 1.0      0.000000          0.549754        1.000000  \n",
       "94                 1.0      0.000000          0.500086        1.000000  \n",
       "95                 1.0      0.000000          0.587268        0.888889  \n",
       "96                 1.0      0.000000          0.792849        0.666667  \n",
       "97                 1.0      0.000000          0.520306        1.000000  \n",
       "98                 1.0      0.500000          0.427849        1.000000  \n",
       "99                 1.0      0.000000          0.563206        1.000000  \n",
       "100                0.0      0.000000          0.385759        1.000000  \n",
       "101                1.0      1.000000          0.596746        1.000000  \n",
       "102                1.0      0.000000          0.452598             NaN  \n",
       "103                1.0      0.000000          0.600621             NaN  \n",
       "104                1.0      0.000000          0.532625        1.000000  \n",
       "105                NaN      0.500000          0.551375             NaN  \n",
       "106                1.0      0.000000          0.493289        1.000000  \n",
       "107                NaN      0.250000          0.590038             NaN  \n",
       "108                1.0      0.000000          0.482208        1.000000  \n",
       "109                1.0      0.000000          0.480373        1.000000  \n",
       "110                1.0      0.000000          0.527792        1.000000  \n",
       "111                1.0      0.500000          0.558629        1.000000  \n",
       "112                1.0      0.666667          0.597411        1.000000  \n",
       "113                1.0      0.000000          0.558433        1.000000  \n",
       "114                1.0      0.500000          0.657085        1.000000  \n",
       "115                1.0      0.333333          0.470692        1.000000  \n",
       "116                1.0      0.000000          0.571664             NaN  \n",
       "117                1.0      0.000000          0.454296        1.000000  \n",
       "118                1.0      0.500000          0.000000        0.333333  \n",
       "119                1.0      0.000000          0.487891        1.000000  \n",
       "120                1.0      0.000000          0.507040        1.000000  \n",
       "121                1.0      0.000000          0.500083        1.000000  \n",
       "122                1.0      0.333333          0.500364        1.000000  \n",
       "123                1.0      1.000000          0.481732        1.000000  \n",
       "124                1.0      1.000000          0.592906        1.000000  \n",
       "125                1.0      0.000000          0.550620        1.000000  \n",
       "126                1.0      0.500000          0.503558        1.000000  \n",
       "127                1.0      0.000000          0.452834        0.400000  \n",
       "128                1.0      0.000000          0.476870             NaN  \n",
       "129                1.0      1.000000          0.513215        1.000000  \n",
       "130                1.0      0.000000          0.525256        1.000000  \n",
       "131                1.0      0.200000          0.656899        1.000000  \n",
       "132                1.0      0.500000          0.547765        1.000000  \n",
       "133                1.0      0.500000          0.536086        1.000000  \n",
       "134                1.0      0.000000          0.655299        1.000000  \n",
       "135                0.0      1.000000          0.734711             NaN  \n",
       "136                1.0      0.000000          0.525309        1.000000  \n",
       "137                1.0      0.000000          0.498547             NaN  \n",
       "138                0.0      0.181818          0.513454        1.000000  \n",
       "139                1.0      0.000000          0.577449             NaN  \n",
       "140                1.0      0.500000          0.480758        1.000000  \n",
       "141                1.0      0.000000          0.452865        1.000000  \n",
       "142                1.0      0.500000          0.572534        1.000000  \n",
       "143                0.0      0.000000          0.511458             NaN  \n",
       "144                1.0      0.000000          0.570273        1.000000  \n",
       "145                1.0      0.000000          0.541880        1.000000  \n",
       "146                NaN      0.500000          0.520118             NaN  \n",
       "147                1.0      0.000000          0.000000        1.000000  \n",
       "148                1.0      0.000000          0.510332        1.000000  \n",
       "149                1.0      0.500000          0.488011        1.000000  \n",
       "150                1.0      0.000000          0.603210        1.000000  \n",
       "151                1.0      0.000000          0.508178        1.000000  \n",
       "152                1.0      0.000000          0.548645        1.000000  \n",
       "153                1.0      0.500000          0.547925        1.000000  \n",
       "154                1.0      0.250000          0.658802        1.000000  \n",
       "155                1.0      1.000000          0.403231        1.000000  \n",
       "156                1.0      0.000000          0.542191        1.000000  \n",
       "157                1.0      0.000000          0.467097             NaN  \n",
       "158                NaN      0.000000          0.573177             NaN  \n",
       "159                1.0      0.000000          0.439208        0.666667  \n",
       "160                1.0      0.500000          0.422628        1.000000  \n",
       "161                1.0      0.000000          0.615110        1.000000  \n",
       "162                1.0      0.000000          0.420886        1.000000  \n",
       "163                1.0      1.000000          0.503343        1.000000  \n",
       "164                0.0      0.333333          0.582231        0.000000  \n",
       "165                1.0      0.500000          0.579978        1.000000  \n",
       "166                1.0      0.000000          0.504691        1.000000  \n",
       "167                1.0      0.500000          0.564241        1.000000  \n",
       "168                1.0      0.000000          0.532581        1.000000  \n",
       "169                1.0      0.000000          0.507008        1.000000  \n",
       "170                0.0      0.000000          0.615981        1.000000  \n",
       "171                1.0      0.000000          0.540919        1.000000  \n",
       "172                1.0      0.400000          0.483384        1.000000  \n",
       "173                0.0      0.000000          0.000000        0.000000  \n",
       "174                1.0      0.000000          0.604758        1.000000  \n",
       "175                0.0      0.000000          0.420323        1.000000  \n",
       "176                1.0      0.000000          0.526680        0.500000  \n",
       "177                NaN      0.000000          0.668446             NaN  \n",
       "178                1.0           NaN          0.580650        1.000000  \n",
       "179                1.0      0.000000          0.419202        1.000000  \n",
       "180                1.0      0.000000          0.528933        1.000000  \n",
       "181                0.0      0.000000          0.592670        0.000000  \n",
       "182                1.0      0.500000          0.534960             NaN  \n",
       "183                1.0      0.333333          0.572198        1.000000  \n",
       "184                1.0      0.000000          0.487650        1.000000  \n",
       "185                1.0      0.000000          0.395714             NaN  \n",
       "186                NaN      0.500000          0.596426             NaN  \n",
       "187                1.0      0.000000          0.400913        0.800000  \n",
       "188                1.0      0.000000          0.431528        1.000000  \n",
       "189                1.0      0.000000          0.502239        1.000000  \n",
       "190                1.0      0.000000          0.535643        1.000000  \n",
       "191                1.0      0.000000          0.599437        1.000000  \n",
       "192                1.0      0.000000          0.850715        1.000000  \n",
       "193                1.0      0.000000          0.629434        0.500000  \n",
       "194                1.0      0.000000          0.460897        0.500000  \n",
       "195                1.0      0.000000          0.407593        0.800000  \n",
       "196                1.0      1.000000          0.478798        1.000000  \n",
       "197                1.0      1.000000          0.182003        1.000000  \n",
       "198                1.0      0.500000          0.568551        1.000000  \n",
       "199                1.0      0.500000          0.513454             NaN  \n",
       "200                1.0      0.000000          0.523667        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "display(pd.read_parquet(\"results.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c03839e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10922' coro=<as_completed.<locals>.sema_coro() running at /Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:37> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:618]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=93 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:726: ResourceWarning: unclosed event loop <_UnixSelectorEventLoop running=False closed=False debug=False>\n",
      "  _warn(f\"unclosed event loop {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Exception ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x315b04f40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 466, in _aevolve\n",
      "    simple_question, current_nodes, _ = await self.se._aevolve(\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 304, in _aevolve\n",
      "    results = await self.generator_llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: coroutine ignored GeneratorExit\n",
      "Exception ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x315b055d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 304, in _aevolve\n",
      "    results = await self.generator_llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: coroutine ignored GeneratorExit\n",
      "Exception ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x315b056c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 304, in _aevolve\n",
      "    results = await self.generator_llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: coroutine ignored GeneratorExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10920' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:35> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:618]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10921' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:35> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:618]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=91>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=98>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=99>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=101>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Exception ignored in: <function ClientResponse.__del__ at 0x176ab3f60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 891, in __del__\n",
      "    self._connection.release()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 173, in release\n",
      "    self._connector._release(\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 667, in _release\n",
      "    protocol.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_proto.py\", line 71, in close\n",
      "    transport.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Exception ignored in: <function ClientResponse.__del__ at 0x176ab3f60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 891, in __del__\n",
      "    self._connection.release()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 173, in release\n",
      "    self._connector._release(\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 667, in _release\n",
      "    protocol.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_proto.py\", line 71, in close\n",
      "    transport.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Exception ignored in: <function ClientResponse.__del__ at 0x176ab3f60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 891, in __del__\n",
      "    self._connection.release()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 173, in release\n",
      "    self._connector._release(\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 667, in _release\n",
      "    protocol.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_proto.py\", line 71, in close\n",
      "    transport.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x311d9fce0>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x30c3c0050>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x311d95ca0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client.py:364: ResourceWarning: Unclosed client session <aiohttp.client.ClientSession object at 0x311d9fce0>\n",
      "  _warnings.warn(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py:119: ResourceWarning: Unclosed connection Connection<ConnectionKey(host='localhost', port=11434, is_ssl=False, ssl=True, proxy=None, proxy_auth=None, proxy_headers_hash=None)>\n",
      "  _warnings.warn(f\"Unclosed connection {self!r}\", ResourceWarning, **kwargs)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client.py:364: ResourceWarning: Unclosed client session <aiohttp.client.ClientSession object at 0x30c3c0050>\n",
      "  _warnings.warn(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client.py:364: ResourceWarning: Unclosed client session <aiohttp.client.ClientSession object at 0x311d95ca0>\n",
      "  _warnings.warn(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=104 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=106>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=111 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=113 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=117>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=116>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x3211317f0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8777): Max retries exceeded with url: /v1/.well-known/ready (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x3211317f0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/connect/connection.py:644\u001b[0m, in \u001b[0;36mConnection.wait_for_weaviate\u001b[0;34m(self, startup_period)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mready_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_request_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINIT_CHECK_TIMEOUT\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8777): Max retries exceeded with url: /v1/.well-known/ready (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x3211317f0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerate_answer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticSearchService\n\u001b[1;32m     11\u001b[0m weaviate_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8777\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m service \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticSearchService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweaviate_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m (questions_list)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# List to store answers (optional)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/eval/generate_answer.py:33\u001b[0m, in \u001b[0;36mSemanticSearchService.__init__\u001b[0;34m(self, weaviate_url)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weaviate_url):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweaviate_url \u001b[38;5;241m=\u001b[39m weaviate_url\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweaviate_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weaviate_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_query_engine()\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/eval/generate_answer.py:37\u001b[0m, in \u001b[0;36mSemanticSearchService.get_weaviate_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weaviate_client\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mweaviate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweaviate_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client\u001b[38;5;241m.\u001b[39mis_live():\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeaviate is not live at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweaviate_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/client.py:150\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, url, auth_client_secret, timeout_config, proxies, trust_env, additional_headers, startup_period, embedded_options, additional_config)\u001b[0m\n\u001b[1;32m    147\u001b[0m config \u001b[38;5;241m=\u001b[39m Config() \u001b[38;5;28;01mif\u001b[39;00m additional_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m additional_config\n\u001b[1;32m    148\u001b[0m url, embedded_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__parse_url_and_embedded_db(url, embedded_options)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[43mConnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_client_secret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_client_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_valid_timeout_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartup_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedded_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrcp_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrpc_port_experimental\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification \u001b[38;5;241m=\u001b[39m Classification(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/connect/connection.py:166\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, url, auth_client_secret, timeout_config, proxies, trust_env, additional_headers, startup_period, connection_config, embedded_db, grcp_port)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startup_period \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     _check_positive_num(startup_period, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartup_period\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m, include_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_weaviate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_sessions(auth_client_secret)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_adapter_to_session(connection_config)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/connect/connection.py:649\u001b[0m, in \u001b[0;36mConnection.wait_for_weaviate\u001b[0;34m(self, startup_period)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (RequestsHTTPError, RequestsConnectionError, ReadTimeout):\n\u001b[0;32m--> 649\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    653\u001b[0m         ready_url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_header(), timeout\u001b[38;5;241m=\u001b[39mINIT_CHECK_TIMEOUT\n\u001b[1;32m    654\u001b[0m     )\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming SemanticSearchParser is your class and it has a method named 'generate_response' that takes a question and returns an answer\n",
    "\n",
    "# Initialize your SemanticSearchParser class\n",
    "# Adjust this step if your class initialization requires different parameters\n",
    "\n",
    "\n",
    "# Now you can import the class\n",
    "\n",
    "from generate_answer import SemanticSearchService\n",
    "\n",
    "weaviate_url = \"http://localhost:8777\"\n",
    "service = SemanticSearchService(weaviate_url)\n",
    "print (questions_list)\n",
    "\n",
    "# List to store answers (optional)\n",
    "answers_list = []\n",
    "\n",
    "\n",
    "# Loop through each question in the questions_list\n",
    "for question in questions_list:\n",
    "    # Use the question as input to get the answer\n",
    "    answer = service.generate_response(question)\n",
    "    \n",
    "    # Print the answer\n",
    "    \n",
    "    # Optionally, append the answer to answers_list for further processing\n",
    "    answers_list.append(answer)\n",
    "\n",
    "print (answers_list)\n",
    "# temp_ans_list = [\"The Janelia Scientific Computing team operates and maintains a world-class computational infrastructure that includes a high-performance compute cluster with over 5000 cores and 300 GPUs. This infrastructure is used to analyze and mine the large amounts of data produced by Janelia's scientists. The team also supports a state-of-the-art storage and compute infrastructure across two data centers, which currently supports over 15 petabytes of scientific data. This data is split across various storage tiers and is connected with an optical fiber ring. The team also maintains a 4500 sq ft data center with significant power and cooling capacity. \\n\\nIn addition to hardware, the team also has deep software skills in a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. These skills are used to help with research and engineering tasks, from quick questions to full software life cycle support. The team's software skills, combined with their domain knowledge in areas such as image processing, machine learning, data handling, microscopy, instrument control, 3D graphics & visualization, and bioinformatics & transcriptomics, allow them to efficiently work with both experimentalists and computer scientists. \\n\\nThe team also develops and maintains a variety of tools and projects, such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher, which are used for various aspects of data analysis and simulation in biological research.\", \"The Janelia Scientific Computing team provides a wide range of support for advanced imaging techniques and image analysis. They offer consultation on experiment design as well as image visualization and processing. They also provide comprehensive image and data analysis support for multiple software packages through hands-on assistance and/or custom-written macros/plugins/scripts for ImageJ/FIJI, MATLAB, Imaris, etc. \\n\\nIn addition, they maintain several computer workstations dedicated to viewing and processing large image datasets acquired with the facility's instruments. These workstations are equipped with a suite of imaging software, including a full version of Imaris, and have robust hardware specifications to handle large datasets. \\n\\nThe team also has deep domain knowledge in image processing, machine learning, data handling, and 3D graphics & visualization, which allows them to efficiently work with experimentalists and computer scientists in various research areas.\", \"The Janelia Scientific Computing team provides world-class computational infrastructure to support the institute's scientific endeavors. They operate and maintain all of Janelias storage and associated backup infrastructure, high performance compute cluster, and all Linux systems. They also manage Janelias data center and backup and disaster recovery resources. The team supports a Linux compute cluster with over 5000 cores and 300 GPUs, and is responsible for maintaining many other Linux servers and workstations. They also handle a significant amount of data, with almost 100TB of new Janelias data being safely backed up every month.\\n\\nIn addition to infrastructure, the Scientific Computing Software team works closely with Janelia's labs and project teams, providing everything from answering quick questions to full software life cycle support. They have a broad range of software skills, including programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They also have deep domain knowledge in areas like image processing, machine learning, data handling, microscopy, instrument control, 3D graphics & visualization, and bioinformatics & transcriptomics. \\n\\nThe team also identifies opportunities for code reuse, reducing development overhead and support costs across Janelia. They are strong proponents of open science and have created the Open Science Software Initiative. Most of their software is open source and available via GitHub. They also run a Scientific Computing Associates program to embed associates in SciComp and the lab or team they work with. \\n\\nThe team is led by Stephan Preibisch and consists of three teams: Software Engineering headed by Konrad Rokicki, Computational Methods and Solutions, both headed by Stephan Preibisch. They have developed several tools and projects like NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher. \\n\\nIn summary, the Janelia Scientific Computing team supports the institute's mission and drives innovation in modern biological research by providing robust computational infrastructure, software support, and developing innovative tools and solutions.\", 'The Janelia Scientific Computing team supports advanced imaging techniques in neuroscience and cell biology through a variety of ways. They have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. They also develop and maintain a range of software tools and applications that aid in these areas. Some of these tools include NeuronBridge for finding neuron matches across modalities, HortaCloud for cloud-based collaborative annotation, VVD Viewer for volumetric rendering of 3D/4D microscopy data, and BigStitcher for efficient alignment of multi-tile and multi-angle image datasets. They also work closely with labs and project teams, providing full software life cycle support.', \"The Janelia Scientific Computing team supports modern biological research in several ways. They maintain a world-class computational infrastructure, including storage and backup infrastructure, a high-performance compute cluster, and all Linux systems. They also manage Janelia's data center and backup and disaster recovery resources. The team supports data storage infrastructure for storing and accessing scientific data, with over 15 petabytes of scientific data split across various storage tiers. They also support a Linux compute cluster with over 5000 cores and 300 GPUs, and maintain many other Linux servers and workstations. \\n\\nIn addition to infrastructure support, the Scientific Computing Software team works closely with Janelia's labs, project teams, and shared resources to help with research and engineering tasks. They provide everything from answering quick questions to full software life cycle support. The team's software skills span a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They also have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. \\n\\nThe team also develops and maintains a variety of tools and projects, such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher. They are strong proponents of open science and most of their software is open source and available via GitHub. They also run the Scientific Computing Associates program, which offers challenging assignments for those interested in computational science.\", \"The Janelia Scientific Computing team provides comprehensive support for advanced imaging techniques in neuroscience, cell biology, and bioinformatics through a variety of collaborations and custom software tools. They work closely with Janelia's labs, project teams, and shared resources to assist with research and engineering tasks. This can range from answering quick questions to providing full software life cycle support.\\n\\nThe team's software skills cover a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. Many team members have backgrounds in biology, enabling them to work efficiently with experimentalists and computer scientists.\\n\\nThe team is also involved in various projects and tools such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher, which are designed to support advanced imaging techniques and data analysis in neuroscience, cell biology, and bioinformatics.\\n\\nFurthermore, the team is a strong proponent of open science and has teamed up with the Computation & Theory research area to create the Open Science Software Initiative. Most of their software is open source and available via GitHub, promoting collaboration and knowledge sharing. They also run the Scientific Computing Associates program, which embeds associates in SciComp and the lab or team they work with.\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699a438",
   "metadata": {},
   "source": [
    "Add values from the list of JaneliaGPT responses to the dataframe[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer'] = None\n",
    "# Assuming df is your DataFrame and answers_list is a list with values to populate the 'Answer' column\n",
    "if len(df) == len(answers_list):\n",
    "    df['answer'] = answers_list\n",
    "else:\n",
    "    print(\"The length of answers_list does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "display(df)\n",
    "# df.to_json('WithAnswersDatasetFromTestTxt.json', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095ca61",
   "metadata": {},
   "source": [
    "Preprocess the dataframe to conver to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55166bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to fix the issue with the answers_list not bsjdkflasdjjfklasdkl fasdjkfh jkas\n",
    "df_fix = df\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['question', 'ground_truth', 'answer', 'contexts']\n",
    "\n",
    "# Reassign df to a DataFrame containing only the columns to keep\n",
    "\n",
    "df_fix= df_fix[columns_to_keep]\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "\n",
    "# Convert 'question' and 'answer' to lists of strings if they are not already\n",
    "# df_fix['question'] = df_fix['question'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "# df_fix['answer'] = df_fix['answer'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "# Ensure 'contexts' and 'ground_truth' are lists of lists of strings\n",
    "# This step assumes 'contexts' and 'ground_truth' are already in the correct format\n",
    "# If not, you would need to apply a similar conversion as above, ensuring each element is a list\n",
    "\n",
    "# Example conversion if 'contexts' and 'ground_truth' were not already lists of lists\n",
    "df_fix['contexts'] = df_fix['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "df_fix['ground_truth'] = df_fix['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "display(df_fix)\n",
    "# Now df should be in the correct format for training\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\")\n",
    "\n",
    "from datasets import Dataset\n",
    "dataset_fix = Dataset.from_pandas(df_fix)\n",
    "dataset_fix = dataset_fix.remove_columns(['__index_level_0__'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e5b0c",
   "metadata": {},
   "source": [
    "Convert dataframe to Dataset and compare to a vaild Dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Features\n",
    "\n",
    "# Assuming dataset_fix and amnesty_qa[\"eval\"] are your datasets\n",
    "features_dataset_fix = dataset_fix.features\n",
    "# features_amnesty_eval = amnesty_qa[\"eval\"].features\n",
    "def format_columns(example):\n",
    "    # Format 'question', 'answer', and 'ground_truths' columns to single values\n",
    "    for column in ['ground_truth', 'answer', 'question']:\n",
    "        if column in example and example[column]:\n",
    "            example[column] = example[column]\n",
    "    \n",
    "    # Correctly format 'contexts' column to a list of list of strings\n",
    "    if 'contexts' in example:\n",
    "        # Ensure 'contexts' is a list of strings (not a list of lists)\n",
    "        if isinstance(example['contexts'], list):\n",
    "            # If the items are lists (or other non-string types), flatten and convert to strings\n",
    "            example['contexts'] = [str(item) for sublist in example['contexts'] for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "        else:\n",
    "            # If 'contexts' is not a list, convert it into a list of a single string\n",
    "            example['contexts'] = [str(example['contexts'])]\n",
    "\n",
    "    \n",
    "    return example\n",
    "\n",
    "\n",
    "# Apply the transformation to both datasets\n",
    "dataset_fix = dataset_fix.map(format_columns)\n",
    "# Direct comparison of data types\n",
    "\"\"\"if set(features_dataset_fix.keys()) == set(features_amnesty_eval.keys()):\n",
    "    all_types_match = True\n",
    "    for key in features_dataset_fix.keys():\n",
    "        type_dataset_fix = type(features_dataset_fix[key]).__name__\n",
    "        type_amnesty_eval = type(features_amnesty_eval[key]).__name__\n",
    "        if type_dataset_fix != type_amnesty_eval:\n",
    "            print(f\"Data type for feature '{key}' differs between datasets. dataset_fix: {type_dataset_fix}, amnesty_qa['eval']: {type_amnesty_eval}\")\n",
    "            all_types_match = False\n",
    "    if all_types_match:\n",
    "        print(\"The data types of all features in both datasets match.\")\n",
    "else:\n",
    "    print(\"The Features of the datasets differ in their keys.\")\"\"\"\n",
    "\"\"\"\n",
    "print (dataset_fix[\"question\"])\n",
    "print (dataset_fix[\"answer\"])\n",
    "print (dataset_fix[\"ground_truth\"])\n",
    "print (dataset_fix[\"contexts\"])\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from deepeval.metrics import (\n",
    "    ContextualPrecisionMetric,\n",
    "    ContextualRecallMetric,\n",
    "    ContextualRelevancyMetric\n",
    ")\n",
    "\n",
    "contextual_precision = ContextualPrecisionMetric()\n",
    "contextual_recall = ContextualRecallMetric()\n",
    "contextual_relevancy = ContextualRelevancyMetric()\n",
    "\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval import evaluate\n",
    "modified_items = []\n",
    "\n",
    "# Step 2: Iterate over each item in dataset_fix\n",
    "for item in dataset_fix:\n",
    "    # Step 3: Create a new LLMTestCase instance with modified fields\n",
    "    modified_item = LLMTestCase(\n",
    "        input=item[\"question\"],\n",
    "        actual_output=item[\"answer\"],\n",
    "        expected_output=item[\"ground_truth\"],\n",
    "        retrieval_context=item[\"contexts\"]\n",
    "    )\n",
    "    # Step 4: Append the modified item to the list\n",
    "    modified_items.append(modified_item)\n",
    "# Assuming dataset_fix supports item assignment\n",
    "\n",
    "\n",
    "\n",
    "evaluate(\n",
    "    test_cases=[modified_items],\n",
    "    metrics=[contextual_precision, contextual_recall, contextual_relevancy]\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2cc907",
   "metadata": {},
   "source": [
    "Run evaluation to gather the below metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "eval_llm = Ollama(model=\"llama3\")\n",
    "# Will reutrn a dataframe with the metrics\n",
    "# Returns error for now because answers column is missing\n",
    "# Error is misleading, fix dataset first and make it match the docs example dataset\n",
    "\n",
    "result = evaluate(\n",
    "    dataset_fix,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=eval_llm,\n",
    ")\n",
    "\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22595923",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "result.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36276909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "import os\n",
    "\n",
    "class MetricsManager:\n",
    "    def __init__(self, file_path='metrics.json'):\n",
    "        self.file_path = file_path\n",
    "        self.metrics = self.load_metrics()\n",
    "\n",
    "    def load_metrics(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, 'r') as file:\n",
    "                return json.load(file)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def save_metrics(self):\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(self.metrics, file, indent=4)\n",
    "\n",
    "    def update_metrics(self, trial_name, context_precision, faithfulness, answer_relevancy, context_recall):\n",
    "        averages = {\n",
    "            'context_precision': context_precision,\n",
    "            'faithfulness': faithfulness,\n",
    "            'answer_relevancy': answer_relevancy,\n",
    "            'context_recall': context_recall\n",
    "        }\n",
    "        self.metrics[trial_name] = averages\n",
    "        self.save_metrics()\n",
    "\n",
    "    def render_table(self):\n",
    "        if not self.metrics:\n",
    "            print(\"No metrics available for plotting.\")\n",
    "            return\n",
    "\n",
    "        trials, metrics, averages = [], [], []\n",
    "        for trial_name, metrics_averages in self.metrics.items():\n",
    "            for metric, average in metrics_averages.items():\n",
    "                trials.append(trial_name)\n",
    "                metrics.append(metric)\n",
    "                averages.append(round(average, 4))\n",
    "\n",
    "        Eval_Categories = pd.DataFrame({\n",
    "            'Trial': trials,\n",
    "            'Metric': metrics,\n",
    "            'Average': averages\n",
    "        })\n",
    "\n",
    "        if Eval_Categories.empty:\n",
    "            print(\"No metrics data to plot.\")\n",
    "            return\n",
    "\n",
    "        fig = px.bar(\n",
    "            Eval_Categories,\n",
    "            x='Trial',\n",
    "            y='Average',\n",
    "            color='Metric',\n",
    "            barmode='group',\n",
    "            text='Average',\n",
    "            category_orders={\"Metric\": [\"context_precision\", \"faithfulness\", \"answer_relevancy\", \"context_recall\"]},\n",
    "            labels={\n",
    "                \"Average\": \"Average Score\",\n",
    "                \"Metric\": \"Metric\",\n",
    "                \"Trial\": \"Trial Name\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=1000,\n",
    "            height=600,\n",
    "            title=\"<b>Average Scores of Evaluation Metrics by Trial</b>\",\n",
    "            xaxis_title=\"Trial Name\",\n",
    "            yaxis_title=\"Average Score\",\n",
    "            font=dict(size=15)\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "MetricsManager()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
